{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on code from https://nextjournal.com/gkoehler/pytorch-mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to produce repeatable results.\n",
    "random_seed = 17\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# NVIDIA CUDA Deep Neural Network (cuDNN) library uses nondeterministic algorithms so they are disabled. \n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Tensor is a multi-dimensional matrix with elements of a single data type.\n",
    "# A Dataset is an abstract class in PyTorch that allows DataLoader to iterate through a given data.\n",
    "# A Dataloader takes in a dataset and a sampler (in this case not specified) and provides an iterable.\n",
    "\n",
    "# Converts a image into a Tensor and normalizes it with mean 0.5 and standard deviation 0.5.\n",
    "transform = torchvision.transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load data for training.\n",
    "train_batch_size = 100\n",
    "train_dataset = torchvision.datasets.MNIST('../data/', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# Load data for testing.\n",
    "test_batch_size = 100\n",
    "test_dataset = torchvision.datasets.MNIST('../data/', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load examples.\n",
    "train_examples = enumerate(train_loader)\n",
    "train_batch_id, (train_example_images, train_example_labels) = next(train_examples)\n",
    "test_examples = enumerate(test_loader)\n",
    "test_batch_id, (test_example_images, test_example_labels) = next(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Batch Size | Channel | Width | Height\n",
      "Train:    100     |    1    |  28   |  28\n",
      "Test :    100     |    1    |  28   |  28\n"
     ]
    }
   ],
   "source": [
    "train_shape = train_example_images.shape\n",
    "test_shape = test_example_images.shape\n",
    "print(\"       Batch Size | Channel | Width | Height\")\n",
    "print(f\"Train:    {train_shape[0]}     |    {train_shape[1]}    |  {train_shape[2]}   |  {train_shape[3]}\")\n",
    "print(f\"Test :    {test_shape[0]}     |    {test_shape[1]}    |  {test_shape[2]}   |  {test_shape[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Example\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train Example\")\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(train_example_images[i][0], cmap=\"gray\")\n",
    "    plt.title(f\"Ground Truth: {train_example_labels[i]}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Example\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Test Example\")\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(test_example_images[i][0], cmap=\"gray\")\n",
    "    plt.title(f\"Ground Truth: {test_example_labels[i]}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network Structure.\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # 2D Convolution: # input channels, # output channels, filter size.\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max Pool 2D: # filter size, stride.\n",
    "        self.pool1 = nn.MaxPool2d(3, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully Connected Layer: # input channels, # output channels.\n",
    "        self.fc1 = nn.Linear(320, 80)\n",
    "        self.fc2 = nn.Linear(80, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Conv -> ReLu -> MaxPool.\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten.\n",
    "        x = x.view(-1, 320)\n",
    "        \n",
    "        # FC -> Relu.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Softmax returns probability of each element in the vector between 0 - 1. \n",
    "        # Final Layer: FC -> Log Softmax.\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer as the name suggests defines how to optimize the model at each iteration.\n",
    "\n",
    "# Basically step size: how much you want to adjust the weights at each iteration.\n",
    "learning_rate = 0.01\n",
    "\n",
    "# How much of the previous update gets applied in current update.\n",
    "momentum = 0.5\n",
    "\n",
    "# Stochastic Gradient Descent.\n",
    "network = CNN()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "log_interval = 10\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "test_losses = []\n",
    "test_counter = [i * len(train_dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \n",
    "    # Set module to training mode.\n",
    "    network.train()\n",
    "    \n",
    "    for train_batch_id, (train_images, train_labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Sets the gradient to zero.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Run CNN.\n",
    "        output = network(train_images)\n",
    "        \n",
    "        # Calculate loss.\n",
    "        # Likelihood: multiply probability class vector with actual label.\n",
    "        # ex) Prediction: [0.1, 0.3, 0.5, 0.1], Ground Truth: [0, 0, 1, 0]\n",
    "        # ex) Likelihood: 0.1 * 0 + 0.3 * 0 + 0.5 * 1 + 0.1 * 0 = 0.5\n",
    "        # Log(1) is 0 and log(negative) = negative. \n",
    "        # Negative log gives you a bigger number as likelihood gets closer to 0.\n",
    "        loss = F.nll_loss(output, train_labels)\n",
    "        \n",
    "        # Computes gradient for every parameter which has requires_grad set to True.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Performs parameter update.\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (train_batch_id + 1) % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, str((train_batch_id + 1) * train_batch_size).rjust(6), len(train_dataset),\n",
    "                100.0 * (train_batch_id + 1) * train_batch_size / len(train_dataset), loss.item()))\n",
    "            \n",
    "            # Append loss and counter.\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(((train_batch_id + 1) * train_batch_size) + ((epoch - 1) * len(train_dataset)))\n",
    "            \n",
    "            # Save internal state\n",
    "            torch.save(network.state_dict(), '../results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), '../results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Test Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    \n",
    "    # Set module to evaluation mode.\n",
    "    network.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    # Temporarily sets all requires_grad to false.\n",
    "    with torch.no_grad():\n",
    "        for test_images, test_labels in test_loader:\n",
    "            \n",
    "            # Run CNN.\n",
    "            output = network(test_images)\n",
    "            \n",
    "            # Calculate sum of loss in batch.\n",
    "            test_loss += F.nll_loss(output, test_labels, reduction=\"sum\").item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            num_correct += pred.eq(test_labels.data.view_as(pred)).sum()\n",
    "        \n",
    "        \n",
    "    test_loss /= len(test_dataset)\n",
    "    test_losses.append(test_loss)\n",
    "        \n",
    "    print('\\nTest Set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, num_correct, len(test_dataset),\n",
    "        100.0 * num_correct / len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set: Avg. loss: 2.3089, Accuracy: 1029/10000 (10%)\n",
      "\n",
      "Train Epoch: 1 [  1000/60000 (2%)]\tLoss: 2.288689\n",
      "Train Epoch: 1 [  2000/60000 (3%)]\tLoss: 2.304722\n",
      "Train Epoch: 1 [  3000/60000 (5%)]\tLoss: 2.272488\n",
      "Train Epoch: 1 [  4000/60000 (7%)]\tLoss: 2.291072\n",
      "Train Epoch: 1 [  5000/60000 (8%)]\tLoss: 2.271198\n",
      "Train Epoch: 1 [  6000/60000 (10%)]\tLoss: 2.273469\n",
      "Train Epoch: 1 [  7000/60000 (12%)]\tLoss: 2.268804\n",
      "Train Epoch: 1 [  8000/60000 (13%)]\tLoss: 2.257021\n",
      "Train Epoch: 1 [  9000/60000 (15%)]\tLoss: 2.238594\n",
      "Train Epoch: 1 [ 10000/60000 (17%)]\tLoss: 2.229197\n",
      "Train Epoch: 1 [ 11000/60000 (18%)]\tLoss: 2.208194\n",
      "Train Epoch: 1 [ 12000/60000 (20%)]\tLoss: 2.205839\n",
      "Train Epoch: 1 [ 13000/60000 (22%)]\tLoss: 2.172714\n",
      "Train Epoch: 1 [ 14000/60000 (23%)]\tLoss: 2.141902\n",
      "Train Epoch: 1 [ 15000/60000 (25%)]\tLoss: 2.123672\n",
      "Train Epoch: 1 [ 16000/60000 (27%)]\tLoss: 2.113586\n",
      "Train Epoch: 1 [ 17000/60000 (28%)]\tLoss: 2.072506\n",
      "Train Epoch: 1 [ 18000/60000 (30%)]\tLoss: 1.976377\n",
      "Train Epoch: 1 [ 19000/60000 (32%)]\tLoss: 1.895087\n",
      "Train Epoch: 1 [ 20000/60000 (33%)]\tLoss: 1.762719\n",
      "Train Epoch: 1 [ 21000/60000 (35%)]\tLoss: 1.725219\n",
      "Train Epoch: 1 [ 22000/60000 (37%)]\tLoss: 1.595590\n",
      "Train Epoch: 1 [ 23000/60000 (38%)]\tLoss: 1.446299\n",
      "Train Epoch: 1 [ 24000/60000 (40%)]\tLoss: 1.300689\n",
      "Train Epoch: 1 [ 25000/60000 (42%)]\tLoss: 1.233598\n",
      "Train Epoch: 1 [ 26000/60000 (43%)]\tLoss: 1.044058\n",
      "Train Epoch: 1 [ 27000/60000 (45%)]\tLoss: 0.858693\n",
      "Train Epoch: 1 [ 28000/60000 (47%)]\tLoss: 0.905596\n",
      "Train Epoch: 1 [ 29000/60000 (48%)]\tLoss: 0.953293\n",
      "Train Epoch: 1 [ 30000/60000 (50%)]\tLoss: 0.755212\n",
      "Train Epoch: 1 [ 31000/60000 (52%)]\tLoss: 0.540713\n",
      "Train Epoch: 1 [ 32000/60000 (53%)]\tLoss: 0.692350\n",
      "Train Epoch: 1 [ 33000/60000 (55%)]\tLoss: 0.531584\n",
      "Train Epoch: 1 [ 34000/60000 (57%)]\tLoss: 0.468950\n",
      "Train Epoch: 1 [ 35000/60000 (58%)]\tLoss: 0.533979\n",
      "Train Epoch: 1 [ 36000/60000 (60%)]\tLoss: 0.385378\n",
      "Train Epoch: 1 [ 37000/60000 (62%)]\tLoss: 0.489351\n",
      "Train Epoch: 1 [ 38000/60000 (63%)]\tLoss: 0.576976\n",
      "Train Epoch: 1 [ 39000/60000 (65%)]\tLoss: 0.502552\n",
      "Train Epoch: 1 [ 40000/60000 (67%)]\tLoss: 0.327691\n",
      "Train Epoch: 1 [ 41000/60000 (68%)]\tLoss: 0.380402\n",
      "Train Epoch: 1 [ 42000/60000 (70%)]\tLoss: 0.447678\n",
      "Train Epoch: 1 [ 43000/60000 (72%)]\tLoss: 0.386770\n",
      "Train Epoch: 1 [ 44000/60000 (73%)]\tLoss: 0.443717\n",
      "Train Epoch: 1 [ 45000/60000 (75%)]\tLoss: 0.415003\n",
      "Train Epoch: 1 [ 46000/60000 (77%)]\tLoss: 0.209322\n",
      "Train Epoch: 1 [ 47000/60000 (78%)]\tLoss: 0.504089\n",
      "Train Epoch: 1 [ 48000/60000 (80%)]\tLoss: 0.301786\n",
      "Train Epoch: 1 [ 49000/60000 (82%)]\tLoss: 0.375272\n",
      "Train Epoch: 1 [ 50000/60000 (83%)]\tLoss: 0.247468\n",
      "Train Epoch: 1 [ 51000/60000 (85%)]\tLoss: 0.297058\n",
      "Train Epoch: 1 [ 52000/60000 (87%)]\tLoss: 0.420018\n",
      "Train Epoch: 1 [ 53000/60000 (88%)]\tLoss: 0.315559\n",
      "Train Epoch: 1 [ 54000/60000 (90%)]\tLoss: 0.295597\n",
      "Train Epoch: 1 [ 55000/60000 (92%)]\tLoss: 0.310532\n",
      "Train Epoch: 1 [ 56000/60000 (93%)]\tLoss: 0.247712\n",
      "Train Epoch: 1 [ 57000/60000 (95%)]\tLoss: 0.415833\n",
      "Train Epoch: 1 [ 58000/60000 (97%)]\tLoss: 0.293296\n",
      "Train Epoch: 1 [ 59000/60000 (98%)]\tLoss: 0.303739\n",
      "Train Epoch: 1 [ 60000/60000 (100%)]\tLoss: 0.257929\n",
      "\n",
      "Test Set: Avg. loss: 0.2427, Accuracy: 9305/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [  1000/60000 (2%)]\tLoss: 0.174427\n",
      "Train Epoch: 2 [  2000/60000 (3%)]\tLoss: 0.151723\n",
      "Train Epoch: 2 [  3000/60000 (5%)]\tLoss: 0.308853\n",
      "Train Epoch: 2 [  4000/60000 (7%)]\tLoss: 0.251416\n",
      "Train Epoch: 2 [  5000/60000 (8%)]\tLoss: 0.298070\n",
      "Train Epoch: 2 [  6000/60000 (10%)]\tLoss: 0.293303\n",
      "Train Epoch: 2 [  7000/60000 (12%)]\tLoss: 0.324293\n",
      "Train Epoch: 2 [  8000/60000 (13%)]\tLoss: 0.159923\n",
      "Train Epoch: 2 [  9000/60000 (15%)]\tLoss: 0.177667\n",
      "Train Epoch: 2 [ 10000/60000 (17%)]\tLoss: 0.165911\n",
      "Train Epoch: 2 [ 11000/60000 (18%)]\tLoss: 0.144155\n",
      "Train Epoch: 2 [ 12000/60000 (20%)]\tLoss: 0.324310\n",
      "Train Epoch: 2 [ 13000/60000 (22%)]\tLoss: 0.204729\n",
      "Train Epoch: 2 [ 14000/60000 (23%)]\tLoss: 0.239107\n",
      "Train Epoch: 2 [ 15000/60000 (25%)]\tLoss: 0.196043\n",
      "Train Epoch: 2 [ 16000/60000 (27%)]\tLoss: 0.172532\n",
      "Train Epoch: 2 [ 17000/60000 (28%)]\tLoss: 0.223276\n",
      "Train Epoch: 2 [ 18000/60000 (30%)]\tLoss: 0.182378\n",
      "Train Epoch: 2 [ 19000/60000 (32%)]\tLoss: 0.167674\n",
      "Train Epoch: 2 [ 20000/60000 (33%)]\tLoss: 0.191571\n",
      "Train Epoch: 2 [ 21000/60000 (35%)]\tLoss: 0.247286\n",
      "Train Epoch: 2 [ 22000/60000 (37%)]\tLoss: 0.126090\n",
      "Train Epoch: 2 [ 23000/60000 (38%)]\tLoss: 0.104487\n",
      "Train Epoch: 2 [ 24000/60000 (40%)]\tLoss: 0.177702\n",
      "Train Epoch: 2 [ 25000/60000 (42%)]\tLoss: 0.156009\n",
      "Train Epoch: 2 [ 26000/60000 (43%)]\tLoss: 0.121317\n",
      "Train Epoch: 2 [ 27000/60000 (45%)]\tLoss: 0.069616\n",
      "Train Epoch: 2 [ 28000/60000 (47%)]\tLoss: 0.243251\n",
      "Train Epoch: 2 [ 29000/60000 (48%)]\tLoss: 0.139022\n",
      "Train Epoch: 2 [ 30000/60000 (50%)]\tLoss: 0.151014\n",
      "Train Epoch: 2 [ 31000/60000 (52%)]\tLoss: 0.138017\n",
      "Train Epoch: 2 [ 32000/60000 (53%)]\tLoss: 0.134133\n",
      "Train Epoch: 2 [ 33000/60000 (55%)]\tLoss: 0.112871\n",
      "Train Epoch: 2 [ 34000/60000 (57%)]\tLoss: 0.140775\n",
      "Train Epoch: 2 [ 35000/60000 (58%)]\tLoss: 0.163299\n",
      "Train Epoch: 2 [ 36000/60000 (60%)]\tLoss: 0.122396\n",
      "Train Epoch: 2 [ 37000/60000 (62%)]\tLoss: 0.163579\n",
      "Train Epoch: 2 [ 38000/60000 (63%)]\tLoss: 0.182826\n",
      "Train Epoch: 2 [ 39000/60000 (65%)]\tLoss: 0.099999\n",
      "Train Epoch: 2 [ 40000/60000 (67%)]\tLoss: 0.148693\n",
      "Train Epoch: 2 [ 41000/60000 (68%)]\tLoss: 0.261471\n",
      "Train Epoch: 2 [ 42000/60000 (70%)]\tLoss: 0.087644\n",
      "Train Epoch: 2 [ 43000/60000 (72%)]\tLoss: 0.264886\n",
      "Train Epoch: 2 [ 44000/60000 (73%)]\tLoss: 0.082048\n",
      "Train Epoch: 2 [ 45000/60000 (75%)]\tLoss: 0.152474\n",
      "Train Epoch: 2 [ 46000/60000 (77%)]\tLoss: 0.103046\n",
      "Train Epoch: 2 [ 47000/60000 (78%)]\tLoss: 0.260222\n",
      "Train Epoch: 2 [ 48000/60000 (80%)]\tLoss: 0.235356\n",
      "Train Epoch: 2 [ 49000/60000 (82%)]\tLoss: 0.226234\n",
      "Train Epoch: 2 [ 50000/60000 (83%)]\tLoss: 0.078458\n",
      "Train Epoch: 2 [ 51000/60000 (85%)]\tLoss: 0.160599\n",
      "Train Epoch: 2 [ 52000/60000 (87%)]\tLoss: 0.134372\n",
      "Train Epoch: 2 [ 53000/60000 (88%)]\tLoss: 0.130724\n",
      "Train Epoch: 2 [ 54000/60000 (90%)]\tLoss: 0.144982\n",
      "Train Epoch: 2 [ 55000/60000 (92%)]\tLoss: 0.060467\n",
      "Train Epoch: 2 [ 56000/60000 (93%)]\tLoss: 0.125741\n",
      "Train Epoch: 2 [ 57000/60000 (95%)]\tLoss: 0.086747\n",
      "Train Epoch: 2 [ 58000/60000 (97%)]\tLoss: 0.142299\n",
      "Train Epoch: 2 [ 59000/60000 (98%)]\tLoss: 0.113417\n",
      "Train Epoch: 2 [ 60000/60000 (100%)]\tLoss: 0.238467\n",
      "\n",
      "Test Set: Avg. loss: 0.1320, Accuracy: 9609/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [  1000/60000 (2%)]\tLoss: 0.098415\n",
      "Train Epoch: 3 [  2000/60000 (3%)]\tLoss: 0.080892\n",
      "Train Epoch: 3 [  3000/60000 (5%)]\tLoss: 0.071088\n",
      "Train Epoch: 3 [  4000/60000 (7%)]\tLoss: 0.144835\n",
      "Train Epoch: 3 [  5000/60000 (8%)]\tLoss: 0.055345\n",
      "Train Epoch: 3 [  6000/60000 (10%)]\tLoss: 0.159845\n",
      "Train Epoch: 3 [  7000/60000 (12%)]\tLoss: 0.259700\n",
      "Train Epoch: 3 [  8000/60000 (13%)]\tLoss: 0.093473\n",
      "Train Epoch: 3 [  9000/60000 (15%)]\tLoss: 0.135321\n",
      "Train Epoch: 3 [ 10000/60000 (17%)]\tLoss: 0.136299\n",
      "Train Epoch: 3 [ 11000/60000 (18%)]\tLoss: 0.103980\n",
      "Train Epoch: 3 [ 12000/60000 (20%)]\tLoss: 0.070445\n",
      "Train Epoch: 3 [ 13000/60000 (22%)]\tLoss: 0.240593\n",
      "Train Epoch: 3 [ 14000/60000 (23%)]\tLoss: 0.157508\n",
      "Train Epoch: 3 [ 15000/60000 (25%)]\tLoss: 0.110369\n",
      "Train Epoch: 3 [ 16000/60000 (27%)]\tLoss: 0.124633\n",
      "Train Epoch: 3 [ 17000/60000 (28%)]\tLoss: 0.166443\n",
      "Train Epoch: 3 [ 18000/60000 (30%)]\tLoss: 0.142261\n",
      "Train Epoch: 3 [ 19000/60000 (32%)]\tLoss: 0.086020\n",
      "Train Epoch: 3 [ 20000/60000 (33%)]\tLoss: 0.170704\n",
      "Train Epoch: 3 [ 21000/60000 (35%)]\tLoss: 0.059783\n",
      "Train Epoch: 3 [ 22000/60000 (37%)]\tLoss: 0.129005\n",
      "Train Epoch: 3 [ 23000/60000 (38%)]\tLoss: 0.068905\n",
      "Train Epoch: 3 [ 24000/60000 (40%)]\tLoss: 0.146445\n",
      "Train Epoch: 3 [ 25000/60000 (42%)]\tLoss: 0.064713\n",
      "Train Epoch: 3 [ 26000/60000 (43%)]\tLoss: 0.076824\n",
      "Train Epoch: 3 [ 27000/60000 (45%)]\tLoss: 0.303355\n",
      "Train Epoch: 3 [ 28000/60000 (47%)]\tLoss: 0.075660\n",
      "Train Epoch: 3 [ 29000/60000 (48%)]\tLoss: 0.137916\n",
      "Train Epoch: 3 [ 30000/60000 (50%)]\tLoss: 0.082588\n",
      "Train Epoch: 3 [ 31000/60000 (52%)]\tLoss: 0.257819\n",
      "Train Epoch: 3 [ 32000/60000 (53%)]\tLoss: 0.109999\n",
      "Train Epoch: 3 [ 33000/60000 (55%)]\tLoss: 0.149377\n",
      "Train Epoch: 3 [ 34000/60000 (57%)]\tLoss: 0.214570\n",
      "Train Epoch: 3 [ 35000/60000 (58%)]\tLoss: 0.087608\n",
      "Train Epoch: 3 [ 36000/60000 (60%)]\tLoss: 0.130239\n",
      "Train Epoch: 3 [ 37000/60000 (62%)]\tLoss: 0.245751\n",
      "Train Epoch: 3 [ 38000/60000 (63%)]\tLoss: 0.189846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [ 39000/60000 (65%)]\tLoss: 0.121224\n",
      "Train Epoch: 3 [ 40000/60000 (67%)]\tLoss: 0.048237\n",
      "Train Epoch: 3 [ 41000/60000 (68%)]\tLoss: 0.208053\n",
      "Train Epoch: 3 [ 42000/60000 (70%)]\tLoss: 0.152795\n",
      "Train Epoch: 3 [ 43000/60000 (72%)]\tLoss: 0.145507\n",
      "Train Epoch: 3 [ 44000/60000 (73%)]\tLoss: 0.180968\n",
      "Train Epoch: 3 [ 45000/60000 (75%)]\tLoss: 0.109231\n",
      "Train Epoch: 3 [ 46000/60000 (77%)]\tLoss: 0.249867\n",
      "Train Epoch: 3 [ 47000/60000 (78%)]\tLoss: 0.117842\n",
      "Train Epoch: 3 [ 48000/60000 (80%)]\tLoss: 0.041425\n",
      "Train Epoch: 3 [ 49000/60000 (82%)]\tLoss: 0.082013\n",
      "Train Epoch: 3 [ 50000/60000 (83%)]\tLoss: 0.053373\n",
      "Train Epoch: 3 [ 51000/60000 (85%)]\tLoss: 0.122817\n",
      "Train Epoch: 3 [ 52000/60000 (87%)]\tLoss: 0.076176\n",
      "Train Epoch: 3 [ 53000/60000 (88%)]\tLoss: 0.113579\n",
      "Train Epoch: 3 [ 54000/60000 (90%)]\tLoss: 0.080507\n",
      "Train Epoch: 3 [ 55000/60000 (92%)]\tLoss: 0.232434\n",
      "Train Epoch: 3 [ 56000/60000 (93%)]\tLoss: 0.105210\n",
      "Train Epoch: 3 [ 57000/60000 (95%)]\tLoss: 0.069088\n",
      "Train Epoch: 3 [ 58000/60000 (97%)]\tLoss: 0.107527\n",
      "Train Epoch: 3 [ 59000/60000 (98%)]\tLoss: 0.163181\n",
      "Train Epoch: 3 [ 60000/60000 (100%)]\tLoss: 0.126672\n",
      "\n",
      "Test Set: Avg. loss: 0.1026, Accuracy: 9668/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [  1000/60000 (2%)]\tLoss: 0.117478\n",
      "Train Epoch: 4 [  2000/60000 (3%)]\tLoss: 0.134759\n",
      "Train Epoch: 4 [  3000/60000 (5%)]\tLoss: 0.092252\n",
      "Train Epoch: 4 [  4000/60000 (7%)]\tLoss: 0.058103\n",
      "Train Epoch: 4 [  5000/60000 (8%)]\tLoss: 0.055333\n",
      "Train Epoch: 4 [  6000/60000 (10%)]\tLoss: 0.120300\n",
      "Train Epoch: 4 [  7000/60000 (12%)]\tLoss: 0.112235\n",
      "Train Epoch: 4 [  8000/60000 (13%)]\tLoss: 0.053842\n",
      "Train Epoch: 4 [  9000/60000 (15%)]\tLoss: 0.043410\n",
      "Train Epoch: 4 [ 10000/60000 (17%)]\tLoss: 0.037516\n",
      "Train Epoch: 4 [ 11000/60000 (18%)]\tLoss: 0.190065\n",
      "Train Epoch: 4 [ 12000/60000 (20%)]\tLoss: 0.113282\n",
      "Train Epoch: 4 [ 13000/60000 (22%)]\tLoss: 0.082623\n",
      "Train Epoch: 4 [ 14000/60000 (23%)]\tLoss: 0.143004\n",
      "Train Epoch: 4 [ 15000/60000 (25%)]\tLoss: 0.124630\n",
      "Train Epoch: 4 [ 16000/60000 (27%)]\tLoss: 0.038451\n",
      "Train Epoch: 4 [ 17000/60000 (28%)]\tLoss: 0.077459\n",
      "Train Epoch: 4 [ 18000/60000 (30%)]\tLoss: 0.092666\n",
      "Train Epoch: 4 [ 19000/60000 (32%)]\tLoss: 0.072379\n",
      "Train Epoch: 4 [ 20000/60000 (33%)]\tLoss: 0.065091\n",
      "Train Epoch: 4 [ 21000/60000 (35%)]\tLoss: 0.055799\n",
      "Train Epoch: 4 [ 22000/60000 (37%)]\tLoss: 0.057943\n",
      "Train Epoch: 4 [ 23000/60000 (38%)]\tLoss: 0.132313\n",
      "Train Epoch: 4 [ 24000/60000 (40%)]\tLoss: 0.047140\n",
      "Train Epoch: 4 [ 25000/60000 (42%)]\tLoss: 0.098336\n",
      "Train Epoch: 4 [ 26000/60000 (43%)]\tLoss: 0.068241\n",
      "Train Epoch: 4 [ 27000/60000 (45%)]\tLoss: 0.108897\n",
      "Train Epoch: 4 [ 28000/60000 (47%)]\tLoss: 0.243455\n",
      "Train Epoch: 4 [ 29000/60000 (48%)]\tLoss: 0.045740\n",
      "Train Epoch: 4 [ 30000/60000 (50%)]\tLoss: 0.131758\n",
      "Train Epoch: 4 [ 31000/60000 (52%)]\tLoss: 0.055936\n",
      "Train Epoch: 4 [ 32000/60000 (53%)]\tLoss: 0.065525\n",
      "Train Epoch: 4 [ 33000/60000 (55%)]\tLoss: 0.108115\n",
      "Train Epoch: 4 [ 34000/60000 (57%)]\tLoss: 0.072224\n",
      "Train Epoch: 4 [ 35000/60000 (58%)]\tLoss: 0.152915\n",
      "Train Epoch: 4 [ 36000/60000 (60%)]\tLoss: 0.104277\n",
      "Train Epoch: 4 [ 37000/60000 (62%)]\tLoss: 0.180689\n",
      "Train Epoch: 4 [ 38000/60000 (63%)]\tLoss: 0.175028\n",
      "Train Epoch: 4 [ 39000/60000 (65%)]\tLoss: 0.116052\n",
      "Train Epoch: 4 [ 40000/60000 (67%)]\tLoss: 0.102762\n",
      "Train Epoch: 4 [ 41000/60000 (68%)]\tLoss: 0.078310\n",
      "Train Epoch: 4 [ 42000/60000 (70%)]\tLoss: 0.077495\n",
      "Train Epoch: 4 [ 43000/60000 (72%)]\tLoss: 0.069982\n",
      "Train Epoch: 4 [ 44000/60000 (73%)]\tLoss: 0.065229\n",
      "Train Epoch: 4 [ 45000/60000 (75%)]\tLoss: 0.099193\n",
      "Train Epoch: 4 [ 46000/60000 (77%)]\tLoss: 0.167367\n",
      "Train Epoch: 4 [ 47000/60000 (78%)]\tLoss: 0.102065\n",
      "Train Epoch: 4 [ 48000/60000 (80%)]\tLoss: 0.103972\n",
      "Train Epoch: 4 [ 49000/60000 (82%)]\tLoss: 0.166347\n",
      "Train Epoch: 4 [ 50000/60000 (83%)]\tLoss: 0.138888\n",
      "Train Epoch: 4 [ 51000/60000 (85%)]\tLoss: 0.042719\n",
      "Train Epoch: 4 [ 52000/60000 (87%)]\tLoss: 0.030621\n",
      "Train Epoch: 4 [ 53000/60000 (88%)]\tLoss: 0.146631\n",
      "Train Epoch: 4 [ 54000/60000 (90%)]\tLoss: 0.231698\n",
      "Train Epoch: 4 [ 55000/60000 (92%)]\tLoss: 0.148803\n",
      "Train Epoch: 4 [ 56000/60000 (93%)]\tLoss: 0.078049\n",
      "Train Epoch: 4 [ 57000/60000 (95%)]\tLoss: 0.088977\n",
      "Train Epoch: 4 [ 58000/60000 (97%)]\tLoss: 0.079113\n",
      "Train Epoch: 4 [ 59000/60000 (98%)]\tLoss: 0.116685\n",
      "Train Epoch: 4 [ 60000/60000 (100%)]\tLoss: 0.073215\n",
      "\n",
      "Test Set: Avg. loss: 0.0766, Accuracy: 9762/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [  1000/60000 (2%)]\tLoss: 0.049379\n",
      "Train Epoch: 5 [  2000/60000 (3%)]\tLoss: 0.055760\n",
      "Train Epoch: 5 [  3000/60000 (5%)]\tLoss: 0.131410\n",
      "Train Epoch: 5 [  4000/60000 (7%)]\tLoss: 0.088572\n",
      "Train Epoch: 5 [  5000/60000 (8%)]\tLoss: 0.077859\n",
      "Train Epoch: 5 [  6000/60000 (10%)]\tLoss: 0.129923\n",
      "Train Epoch: 5 [  7000/60000 (12%)]\tLoss: 0.140434\n",
      "Train Epoch: 5 [  8000/60000 (13%)]\tLoss: 0.087218\n",
      "Train Epoch: 5 [  9000/60000 (15%)]\tLoss: 0.060432\n",
      "Train Epoch: 5 [ 10000/60000 (17%)]\tLoss: 0.085123\n",
      "Train Epoch: 5 [ 11000/60000 (18%)]\tLoss: 0.090616\n",
      "Train Epoch: 5 [ 12000/60000 (20%)]\tLoss: 0.100346\n",
      "Train Epoch: 5 [ 13000/60000 (22%)]\tLoss: 0.069508\n",
      "Train Epoch: 5 [ 14000/60000 (23%)]\tLoss: 0.040084\n",
      "Train Epoch: 5 [ 15000/60000 (25%)]\tLoss: 0.087020\n",
      "Train Epoch: 5 [ 16000/60000 (27%)]\tLoss: 0.157324\n",
      "Train Epoch: 5 [ 17000/60000 (28%)]\tLoss: 0.154144\n",
      "Train Epoch: 5 [ 18000/60000 (30%)]\tLoss: 0.195568\n",
      "Train Epoch: 5 [ 19000/60000 (32%)]\tLoss: 0.061933\n",
      "Train Epoch: 5 [ 20000/60000 (33%)]\tLoss: 0.081497\n",
      "Train Epoch: 5 [ 21000/60000 (35%)]\tLoss: 0.028832\n",
      "Train Epoch: 5 [ 22000/60000 (37%)]\tLoss: 0.105518\n",
      "Train Epoch: 5 [ 23000/60000 (38%)]\tLoss: 0.080613\n",
      "Train Epoch: 5 [ 24000/60000 (40%)]\tLoss: 0.064481\n",
      "Train Epoch: 5 [ 25000/60000 (42%)]\tLoss: 0.119635\n",
      "Train Epoch: 5 [ 26000/60000 (43%)]\tLoss: 0.038665\n",
      "Train Epoch: 5 [ 27000/60000 (45%)]\tLoss: 0.070143\n",
      "Train Epoch: 5 [ 28000/60000 (47%)]\tLoss: 0.023539\n",
      "Train Epoch: 5 [ 29000/60000 (48%)]\tLoss: 0.041092\n",
      "Train Epoch: 5 [ 30000/60000 (50%)]\tLoss: 0.098970\n",
      "Train Epoch: 5 [ 31000/60000 (52%)]\tLoss: 0.059902\n",
      "Train Epoch: 5 [ 32000/60000 (53%)]\tLoss: 0.041168\n",
      "Train Epoch: 5 [ 33000/60000 (55%)]\tLoss: 0.052166\n",
      "Train Epoch: 5 [ 34000/60000 (57%)]\tLoss: 0.033869\n",
      "Train Epoch: 5 [ 35000/60000 (58%)]\tLoss: 0.096209\n",
      "Train Epoch: 5 [ 36000/60000 (60%)]\tLoss: 0.064820\n",
      "Train Epoch: 5 [ 37000/60000 (62%)]\tLoss: 0.069717\n",
      "Train Epoch: 5 [ 38000/60000 (63%)]\tLoss: 0.039847\n",
      "Train Epoch: 5 [ 39000/60000 (65%)]\tLoss: 0.131262\n",
      "Train Epoch: 5 [ 40000/60000 (67%)]\tLoss: 0.104920\n",
      "Train Epoch: 5 [ 41000/60000 (68%)]\tLoss: 0.150578\n",
      "Train Epoch: 5 [ 42000/60000 (70%)]\tLoss: 0.072852\n",
      "Train Epoch: 5 [ 43000/60000 (72%)]\tLoss: 0.125740\n",
      "Train Epoch: 5 [ 44000/60000 (73%)]\tLoss: 0.066886\n",
      "Train Epoch: 5 [ 45000/60000 (75%)]\tLoss: 0.159012\n",
      "Train Epoch: 5 [ 46000/60000 (77%)]\tLoss: 0.166670\n",
      "Train Epoch: 5 [ 47000/60000 (78%)]\tLoss: 0.103450\n",
      "Train Epoch: 5 [ 48000/60000 (80%)]\tLoss: 0.065012\n",
      "Train Epoch: 5 [ 49000/60000 (82%)]\tLoss: 0.079318\n",
      "Train Epoch: 5 [ 50000/60000 (83%)]\tLoss: 0.211226\n",
      "Train Epoch: 5 [ 51000/60000 (85%)]\tLoss: 0.080676\n",
      "Train Epoch: 5 [ 52000/60000 (87%)]\tLoss: 0.052969\n",
      "Train Epoch: 5 [ 53000/60000 (88%)]\tLoss: 0.118368\n",
      "Train Epoch: 5 [ 54000/60000 (90%)]\tLoss: 0.053315\n",
      "Train Epoch: 5 [ 55000/60000 (92%)]\tLoss: 0.091630\n",
      "Train Epoch: 5 [ 56000/60000 (93%)]\tLoss: 0.024558\n",
      "Train Epoch: 5 [ 57000/60000 (95%)]\tLoss: 0.074941\n",
      "Train Epoch: 5 [ 58000/60000 (97%)]\tLoss: 0.164126\n",
      "Train Epoch: 5 [ 59000/60000 (98%)]\tLoss: 0.099810\n",
      "Train Epoch: 5 [ 60000/60000 (100%)]\tLoss: 0.066249\n",
      "\n",
      "Test Set: Avg. loss: 0.0762, Accuracy: 9770/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [  1000/60000 (2%)]\tLoss: 0.033400\n",
      "Train Epoch: 6 [  2000/60000 (3%)]\tLoss: 0.097910\n",
      "Train Epoch: 6 [  3000/60000 (5%)]\tLoss: 0.039794\n",
      "Train Epoch: 6 [  4000/60000 (7%)]\tLoss: 0.087348\n",
      "Train Epoch: 6 [  5000/60000 (8%)]\tLoss: 0.082342\n",
      "Train Epoch: 6 [  6000/60000 (10%)]\tLoss: 0.133114\n",
      "Train Epoch: 6 [  7000/60000 (12%)]\tLoss: 0.033457\n",
      "Train Epoch: 6 [  8000/60000 (13%)]\tLoss: 0.054843\n",
      "Train Epoch: 6 [  9000/60000 (15%)]\tLoss: 0.079637\n",
      "Train Epoch: 6 [ 10000/60000 (17%)]\tLoss: 0.088070\n",
      "Train Epoch: 6 [ 11000/60000 (18%)]\tLoss: 0.033556\n",
      "Train Epoch: 6 [ 12000/60000 (20%)]\tLoss: 0.025010\n",
      "Train Epoch: 6 [ 13000/60000 (22%)]\tLoss: 0.029600\n",
      "Train Epoch: 6 [ 14000/60000 (23%)]\tLoss: 0.134724\n",
      "Train Epoch: 6 [ 15000/60000 (25%)]\tLoss: 0.092623\n",
      "Train Epoch: 6 [ 16000/60000 (27%)]\tLoss: 0.072451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [ 17000/60000 (28%)]\tLoss: 0.068936\n",
      "Train Epoch: 6 [ 18000/60000 (30%)]\tLoss: 0.040004\n",
      "Train Epoch: 6 [ 19000/60000 (32%)]\tLoss: 0.029973\n",
      "Train Epoch: 6 [ 20000/60000 (33%)]\tLoss: 0.067066\n",
      "Train Epoch: 6 [ 21000/60000 (35%)]\tLoss: 0.060208\n",
      "Train Epoch: 6 [ 22000/60000 (37%)]\tLoss: 0.053783\n",
      "Train Epoch: 6 [ 23000/60000 (38%)]\tLoss: 0.113908\n",
      "Train Epoch: 6 [ 24000/60000 (40%)]\tLoss: 0.032666\n",
      "Train Epoch: 6 [ 25000/60000 (42%)]\tLoss: 0.113313\n",
      "Train Epoch: 6 [ 26000/60000 (43%)]\tLoss: 0.084827\n",
      "Train Epoch: 6 [ 27000/60000 (45%)]\tLoss: 0.150472\n",
      "Train Epoch: 6 [ 28000/60000 (47%)]\tLoss: 0.024281\n",
      "Train Epoch: 6 [ 29000/60000 (48%)]\tLoss: 0.065262\n",
      "Train Epoch: 6 [ 30000/60000 (50%)]\tLoss: 0.062204\n",
      "Train Epoch: 6 [ 31000/60000 (52%)]\tLoss: 0.039041\n",
      "Train Epoch: 6 [ 32000/60000 (53%)]\tLoss: 0.021495\n",
      "Train Epoch: 6 [ 33000/60000 (55%)]\tLoss: 0.094228\n",
      "Train Epoch: 6 [ 34000/60000 (57%)]\tLoss: 0.085770\n",
      "Train Epoch: 6 [ 35000/60000 (58%)]\tLoss: 0.067510\n",
      "Train Epoch: 6 [ 36000/60000 (60%)]\tLoss: 0.172516\n",
      "Train Epoch: 6 [ 37000/60000 (62%)]\tLoss: 0.059790\n",
      "Train Epoch: 6 [ 38000/60000 (63%)]\tLoss: 0.040226\n",
      "Train Epoch: 6 [ 39000/60000 (65%)]\tLoss: 0.077610\n",
      "Train Epoch: 6 [ 40000/60000 (67%)]\tLoss: 0.019838\n",
      "Train Epoch: 6 [ 41000/60000 (68%)]\tLoss: 0.063925\n",
      "Train Epoch: 6 [ 42000/60000 (70%)]\tLoss: 0.053765\n",
      "Train Epoch: 6 [ 43000/60000 (72%)]\tLoss: 0.065270\n",
      "Train Epoch: 6 [ 44000/60000 (73%)]\tLoss: 0.052506\n",
      "Train Epoch: 6 [ 45000/60000 (75%)]\tLoss: 0.045370\n",
      "Train Epoch: 6 [ 46000/60000 (77%)]\tLoss: 0.113463\n",
      "Train Epoch: 6 [ 47000/60000 (78%)]\tLoss: 0.122150\n",
      "Train Epoch: 6 [ 48000/60000 (80%)]\tLoss: 0.162273\n",
      "Train Epoch: 6 [ 49000/60000 (82%)]\tLoss: 0.018992\n",
      "Train Epoch: 6 [ 50000/60000 (83%)]\tLoss: 0.060252\n",
      "Train Epoch: 6 [ 51000/60000 (85%)]\tLoss: 0.092357\n",
      "Train Epoch: 6 [ 52000/60000 (87%)]\tLoss: 0.166023\n",
      "Train Epoch: 6 [ 53000/60000 (88%)]\tLoss: 0.270052\n",
      "Train Epoch: 6 [ 54000/60000 (90%)]\tLoss: 0.093386\n",
      "Train Epoch: 6 [ 55000/60000 (92%)]\tLoss: 0.017668\n",
      "Train Epoch: 6 [ 56000/60000 (93%)]\tLoss: 0.140650\n",
      "Train Epoch: 6 [ 57000/60000 (95%)]\tLoss: 0.052570\n",
      "Train Epoch: 6 [ 58000/60000 (97%)]\tLoss: 0.047879\n",
      "Train Epoch: 6 [ 59000/60000 (98%)]\tLoss: 0.040861\n",
      "Train Epoch: 6 [ 60000/60000 (100%)]\tLoss: 0.097814\n",
      "\n",
      "Test Set: Avg. loss: 0.0651, Accuracy: 9800/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [  1000/60000 (2%)]\tLoss: 0.064367\n",
      "Train Epoch: 7 [  2000/60000 (3%)]\tLoss: 0.092351\n",
      "Train Epoch: 7 [  3000/60000 (5%)]\tLoss: 0.047482\n",
      "Train Epoch: 7 [  4000/60000 (7%)]\tLoss: 0.059045\n",
      "Train Epoch: 7 [  5000/60000 (8%)]\tLoss: 0.129558\n",
      "Train Epoch: 7 [  6000/60000 (10%)]\tLoss: 0.024815\n",
      "Train Epoch: 7 [  7000/60000 (12%)]\tLoss: 0.081679\n",
      "Train Epoch: 7 [  8000/60000 (13%)]\tLoss: 0.040765\n",
      "Train Epoch: 7 [  9000/60000 (15%)]\tLoss: 0.037514\n",
      "Train Epoch: 7 [ 10000/60000 (17%)]\tLoss: 0.068484\n",
      "Train Epoch: 7 [ 11000/60000 (18%)]\tLoss: 0.047643\n",
      "Train Epoch: 7 [ 12000/60000 (20%)]\tLoss: 0.034317\n",
      "Train Epoch: 7 [ 13000/60000 (22%)]\tLoss: 0.031326\n",
      "Train Epoch: 7 [ 14000/60000 (23%)]\tLoss: 0.049175\n",
      "Train Epoch: 7 [ 15000/60000 (25%)]\tLoss: 0.075773\n",
      "Train Epoch: 7 [ 16000/60000 (27%)]\tLoss: 0.018717\n",
      "Train Epoch: 7 [ 17000/60000 (28%)]\tLoss: 0.070330\n",
      "Train Epoch: 7 [ 18000/60000 (30%)]\tLoss: 0.053970\n",
      "Train Epoch: 7 [ 19000/60000 (32%)]\tLoss: 0.077149\n",
      "Train Epoch: 7 [ 20000/60000 (33%)]\tLoss: 0.116321\n",
      "Train Epoch: 7 [ 21000/60000 (35%)]\tLoss: 0.067853\n",
      "Train Epoch: 7 [ 22000/60000 (37%)]\tLoss: 0.033201\n",
      "Train Epoch: 7 [ 23000/60000 (38%)]\tLoss: 0.100780\n",
      "Train Epoch: 7 [ 24000/60000 (40%)]\tLoss: 0.045624\n",
      "Train Epoch: 7 [ 25000/60000 (42%)]\tLoss: 0.025433\n",
      "Train Epoch: 7 [ 26000/60000 (43%)]\tLoss: 0.022083\n",
      "Train Epoch: 7 [ 27000/60000 (45%)]\tLoss: 0.104748\n",
      "Train Epoch: 7 [ 28000/60000 (47%)]\tLoss: 0.044121\n",
      "Train Epoch: 7 [ 29000/60000 (48%)]\tLoss: 0.192307\n",
      "Train Epoch: 7 [ 30000/60000 (50%)]\tLoss: 0.075288\n",
      "Train Epoch: 7 [ 31000/60000 (52%)]\tLoss: 0.019754\n",
      "Train Epoch: 7 [ 32000/60000 (53%)]\tLoss: 0.056939\n",
      "Train Epoch: 7 [ 33000/60000 (55%)]\tLoss: 0.038413\n",
      "Train Epoch: 7 [ 34000/60000 (57%)]\tLoss: 0.101960\n",
      "Train Epoch: 7 [ 35000/60000 (58%)]\tLoss: 0.051585\n",
      "Train Epoch: 7 [ 36000/60000 (60%)]\tLoss: 0.127217\n",
      "Train Epoch: 7 [ 37000/60000 (62%)]\tLoss: 0.044429\n",
      "Train Epoch: 7 [ 38000/60000 (63%)]\tLoss: 0.078064\n",
      "Train Epoch: 7 [ 39000/60000 (65%)]\tLoss: 0.016362\n",
      "Train Epoch: 7 [ 40000/60000 (67%)]\tLoss: 0.100971\n",
      "Train Epoch: 7 [ 41000/60000 (68%)]\tLoss: 0.062202\n",
      "Train Epoch: 7 [ 42000/60000 (70%)]\tLoss: 0.063659\n",
      "Train Epoch: 7 [ 43000/60000 (72%)]\tLoss: 0.098667\n",
      "Train Epoch: 7 [ 44000/60000 (73%)]\tLoss: 0.064783\n",
      "Train Epoch: 7 [ 45000/60000 (75%)]\tLoss: 0.076447\n",
      "Train Epoch: 7 [ 46000/60000 (77%)]\tLoss: 0.067052\n",
      "Train Epoch: 7 [ 47000/60000 (78%)]\tLoss: 0.067115\n",
      "Train Epoch: 7 [ 48000/60000 (80%)]\tLoss: 0.068660\n",
      "Train Epoch: 7 [ 49000/60000 (82%)]\tLoss: 0.059573\n",
      "Train Epoch: 7 [ 50000/60000 (83%)]\tLoss: 0.025772\n",
      "Train Epoch: 7 [ 51000/60000 (85%)]\tLoss: 0.021730\n",
      "Train Epoch: 7 [ 52000/60000 (87%)]\tLoss: 0.040715\n",
      "Train Epoch: 7 [ 53000/60000 (88%)]\tLoss: 0.074840\n",
      "Train Epoch: 7 [ 54000/60000 (90%)]\tLoss: 0.066500\n",
      "Train Epoch: 7 [ 55000/60000 (92%)]\tLoss: 0.041952\n",
      "Train Epoch: 7 [ 56000/60000 (93%)]\tLoss: 0.155776\n",
      "Train Epoch: 7 [ 57000/60000 (95%)]\tLoss: 0.076508\n",
      "Train Epoch: 7 [ 58000/60000 (97%)]\tLoss: 0.043879\n",
      "Train Epoch: 7 [ 59000/60000 (98%)]\tLoss: 0.040554\n",
      "Train Epoch: 7 [ 60000/60000 (100%)]\tLoss: 0.060723\n",
      "\n",
      "Test Set: Avg. loss: 0.0718, Accuracy: 9767/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [  1000/60000 (2%)]\tLoss: 0.058077\n",
      "Train Epoch: 8 [  2000/60000 (3%)]\tLoss: 0.012193\n",
      "Train Epoch: 8 [  3000/60000 (5%)]\tLoss: 0.159513\n",
      "Train Epoch: 8 [  4000/60000 (7%)]\tLoss: 0.025721\n",
      "Train Epoch: 8 [  5000/60000 (8%)]\tLoss: 0.045290\n",
      "Train Epoch: 8 [  6000/60000 (10%)]\tLoss: 0.117460\n",
      "Train Epoch: 8 [  7000/60000 (12%)]\tLoss: 0.110923\n",
      "Train Epoch: 8 [  8000/60000 (13%)]\tLoss: 0.076880\n",
      "Train Epoch: 8 [  9000/60000 (15%)]\tLoss: 0.050438\n",
      "Train Epoch: 8 [ 10000/60000 (17%)]\tLoss: 0.146230\n",
      "Train Epoch: 8 [ 11000/60000 (18%)]\tLoss: 0.034949\n",
      "Train Epoch: 8 [ 12000/60000 (20%)]\tLoss: 0.054381\n",
      "Train Epoch: 8 [ 13000/60000 (22%)]\tLoss: 0.054015\n",
      "Train Epoch: 8 [ 14000/60000 (23%)]\tLoss: 0.045413\n",
      "Train Epoch: 8 [ 15000/60000 (25%)]\tLoss: 0.047584\n",
      "Train Epoch: 8 [ 16000/60000 (27%)]\tLoss: 0.021241\n",
      "Train Epoch: 8 [ 17000/60000 (28%)]\tLoss: 0.061695\n",
      "Train Epoch: 8 [ 18000/60000 (30%)]\tLoss: 0.067830\n",
      "Train Epoch: 8 [ 19000/60000 (32%)]\tLoss: 0.120060\n",
      "Train Epoch: 8 [ 20000/60000 (33%)]\tLoss: 0.014525\n",
      "Train Epoch: 8 [ 21000/60000 (35%)]\tLoss: 0.017890\n",
      "Train Epoch: 8 [ 22000/60000 (37%)]\tLoss: 0.028254\n",
      "Train Epoch: 8 [ 23000/60000 (38%)]\tLoss: 0.069908\n",
      "Train Epoch: 8 [ 24000/60000 (40%)]\tLoss: 0.041590\n",
      "Train Epoch: 8 [ 25000/60000 (42%)]\tLoss: 0.108901\n",
      "Train Epoch: 8 [ 26000/60000 (43%)]\tLoss: 0.080433\n",
      "Train Epoch: 8 [ 27000/60000 (45%)]\tLoss: 0.023842\n",
      "Train Epoch: 8 [ 28000/60000 (47%)]\tLoss: 0.038035\n",
      "Train Epoch: 8 [ 29000/60000 (48%)]\tLoss: 0.049574\n",
      "Train Epoch: 8 [ 30000/60000 (50%)]\tLoss: 0.071602\n",
      "Train Epoch: 8 [ 31000/60000 (52%)]\tLoss: 0.065839\n",
      "Train Epoch: 8 [ 32000/60000 (53%)]\tLoss: 0.048421\n",
      "Train Epoch: 8 [ 33000/60000 (55%)]\tLoss: 0.027338\n",
      "Train Epoch: 8 [ 34000/60000 (57%)]\tLoss: 0.045901\n",
      "Train Epoch: 8 [ 35000/60000 (58%)]\tLoss: 0.124593\n",
      "Train Epoch: 8 [ 36000/60000 (60%)]\tLoss: 0.057553\n",
      "Train Epoch: 8 [ 37000/60000 (62%)]\tLoss: 0.085491\n",
      "Train Epoch: 8 [ 38000/60000 (63%)]\tLoss: 0.053291\n",
      "Train Epoch: 8 [ 39000/60000 (65%)]\tLoss: 0.068546\n",
      "Train Epoch: 8 [ 40000/60000 (67%)]\tLoss: 0.102493\n",
      "Train Epoch: 8 [ 41000/60000 (68%)]\tLoss: 0.063899\n",
      "Train Epoch: 8 [ 42000/60000 (70%)]\tLoss: 0.075113\n",
      "Train Epoch: 8 [ 43000/60000 (72%)]\tLoss: 0.022588\n",
      "Train Epoch: 8 [ 44000/60000 (73%)]\tLoss: 0.015351\n",
      "Train Epoch: 8 [ 45000/60000 (75%)]\tLoss: 0.085611\n",
      "Train Epoch: 8 [ 46000/60000 (77%)]\tLoss: 0.028971\n",
      "Train Epoch: 8 [ 47000/60000 (78%)]\tLoss: 0.063857\n",
      "Train Epoch: 8 [ 48000/60000 (80%)]\tLoss: 0.182272\n",
      "Train Epoch: 8 [ 49000/60000 (82%)]\tLoss: 0.047920\n",
      "Train Epoch: 8 [ 50000/60000 (83%)]\tLoss: 0.042714\n",
      "Train Epoch: 8 [ 51000/60000 (85%)]\tLoss: 0.102779\n",
      "Train Epoch: 8 [ 52000/60000 (87%)]\tLoss: 0.048228\n",
      "Train Epoch: 8 [ 53000/60000 (88%)]\tLoss: 0.042832\n",
      "Train Epoch: 8 [ 54000/60000 (90%)]\tLoss: 0.060049\n",
      "Train Epoch: 8 [ 55000/60000 (92%)]\tLoss: 0.045232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [ 56000/60000 (93%)]\tLoss: 0.093856\n",
      "Train Epoch: 8 [ 57000/60000 (95%)]\tLoss: 0.121177\n",
      "Train Epoch: 8 [ 58000/60000 (97%)]\tLoss: 0.060498\n",
      "Train Epoch: 8 [ 59000/60000 (98%)]\tLoss: 0.075914\n",
      "Train Epoch: 8 [ 60000/60000 (100%)]\tLoss: 0.037563\n",
      "\n",
      "Test Set: Avg. loss: 0.0546, Accuracy: 9825/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [  1000/60000 (2%)]\tLoss: 0.009891\n",
      "Train Epoch: 9 [  2000/60000 (3%)]\tLoss: 0.012992\n",
      "Train Epoch: 9 [  3000/60000 (5%)]\tLoss: 0.025651\n",
      "Train Epoch: 9 [  4000/60000 (7%)]\tLoss: 0.054240\n",
      "Train Epoch: 9 [  5000/60000 (8%)]\tLoss: 0.096020\n",
      "Train Epoch: 9 [  6000/60000 (10%)]\tLoss: 0.060756\n",
      "Train Epoch: 9 [  7000/60000 (12%)]\tLoss: 0.078113\n",
      "Train Epoch: 9 [  8000/60000 (13%)]\tLoss: 0.026645\n",
      "Train Epoch: 9 [  9000/60000 (15%)]\tLoss: 0.055476\n",
      "Train Epoch: 9 [ 10000/60000 (17%)]\tLoss: 0.081673\n",
      "Train Epoch: 9 [ 11000/60000 (18%)]\tLoss: 0.026908\n",
      "Train Epoch: 9 [ 12000/60000 (20%)]\tLoss: 0.086569\n",
      "Train Epoch: 9 [ 13000/60000 (22%)]\tLoss: 0.101584\n",
      "Train Epoch: 9 [ 14000/60000 (23%)]\tLoss: 0.019196\n",
      "Train Epoch: 9 [ 15000/60000 (25%)]\tLoss: 0.017515\n",
      "Train Epoch: 9 [ 16000/60000 (27%)]\tLoss: 0.070102\n",
      "Train Epoch: 9 [ 17000/60000 (28%)]\tLoss: 0.085501\n",
      "Train Epoch: 9 [ 18000/60000 (30%)]\tLoss: 0.043859\n",
      "Train Epoch: 9 [ 19000/60000 (32%)]\tLoss: 0.087665\n",
      "Train Epoch: 9 [ 20000/60000 (33%)]\tLoss: 0.098072\n",
      "Train Epoch: 9 [ 21000/60000 (35%)]\tLoss: 0.085792\n",
      "Train Epoch: 9 [ 22000/60000 (37%)]\tLoss: 0.029374\n",
      "Train Epoch: 9 [ 23000/60000 (38%)]\tLoss: 0.021612\n",
      "Train Epoch: 9 [ 24000/60000 (40%)]\tLoss: 0.040887\n",
      "Train Epoch: 9 [ 25000/60000 (42%)]\tLoss: 0.051707\n",
      "Train Epoch: 9 [ 26000/60000 (43%)]\tLoss: 0.076315\n",
      "Train Epoch: 9 [ 27000/60000 (45%)]\tLoss: 0.039704\n",
      "Train Epoch: 9 [ 28000/60000 (47%)]\tLoss: 0.035719\n",
      "Train Epoch: 9 [ 29000/60000 (48%)]\tLoss: 0.079395\n",
      "Train Epoch: 9 [ 30000/60000 (50%)]\tLoss: 0.068275\n",
      "Train Epoch: 9 [ 31000/60000 (52%)]\tLoss: 0.071523\n",
      "Train Epoch: 9 [ 32000/60000 (53%)]\tLoss: 0.133314\n",
      "Train Epoch: 9 [ 33000/60000 (55%)]\tLoss: 0.064263\n",
      "Train Epoch: 9 [ 34000/60000 (57%)]\tLoss: 0.135847\n",
      "Train Epoch: 9 [ 35000/60000 (58%)]\tLoss: 0.018769\n",
      "Train Epoch: 9 [ 36000/60000 (60%)]\tLoss: 0.016376\n",
      "Train Epoch: 9 [ 37000/60000 (62%)]\tLoss: 0.081835\n",
      "Train Epoch: 9 [ 38000/60000 (63%)]\tLoss: 0.057632\n",
      "Train Epoch: 9 [ 39000/60000 (65%)]\tLoss: 0.114959\n",
      "Train Epoch: 9 [ 40000/60000 (67%)]\tLoss: 0.039699\n",
      "Train Epoch: 9 [ 41000/60000 (68%)]\tLoss: 0.063815\n",
      "Train Epoch: 9 [ 42000/60000 (70%)]\tLoss: 0.117201\n",
      "Train Epoch: 9 [ 43000/60000 (72%)]\tLoss: 0.076640\n",
      "Train Epoch: 9 [ 44000/60000 (73%)]\tLoss: 0.056204\n",
      "Train Epoch: 9 [ 45000/60000 (75%)]\tLoss: 0.093273\n",
      "Train Epoch: 9 [ 46000/60000 (77%)]\tLoss: 0.045023\n",
      "Train Epoch: 9 [ 47000/60000 (78%)]\tLoss: 0.118558\n",
      "Train Epoch: 9 [ 48000/60000 (80%)]\tLoss: 0.013215\n",
      "Train Epoch: 9 [ 49000/60000 (82%)]\tLoss: 0.018919\n",
      "Train Epoch: 9 [ 50000/60000 (83%)]\tLoss: 0.069977\n",
      "Train Epoch: 9 [ 51000/60000 (85%)]\tLoss: 0.128276\n",
      "Train Epoch: 9 [ 52000/60000 (87%)]\tLoss: 0.064563\n",
      "Train Epoch: 9 [ 53000/60000 (88%)]\tLoss: 0.034809\n",
      "Train Epoch: 9 [ 54000/60000 (90%)]\tLoss: 0.051151\n",
      "Train Epoch: 9 [ 55000/60000 (92%)]\tLoss: 0.054633\n",
      "Train Epoch: 9 [ 56000/60000 (93%)]\tLoss: 0.044251\n",
      "Train Epoch: 9 [ 57000/60000 (95%)]\tLoss: 0.074292\n",
      "Train Epoch: 9 [ 58000/60000 (97%)]\tLoss: 0.061832\n",
      "Train Epoch: 9 [ 59000/60000 (98%)]\tLoss: 0.040212\n",
      "Train Epoch: 9 [ 60000/60000 (100%)]\tLoss: 0.116914\n",
      "\n",
      "Test Set: Avg. loss: 0.0503, Accuracy: 9835/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [  1000/60000 (2%)]\tLoss: 0.146296\n",
      "Train Epoch: 10 [  2000/60000 (3%)]\tLoss: 0.070945\n",
      "Train Epoch: 10 [  3000/60000 (5%)]\tLoss: 0.033181\n",
      "Train Epoch: 10 [  4000/60000 (7%)]\tLoss: 0.086194\n",
      "Train Epoch: 10 [  5000/60000 (8%)]\tLoss: 0.029615\n",
      "Train Epoch: 10 [  6000/60000 (10%)]\tLoss: 0.033393\n",
      "Train Epoch: 10 [  7000/60000 (12%)]\tLoss: 0.019094\n",
      "Train Epoch: 10 [  8000/60000 (13%)]\tLoss: 0.039943\n",
      "Train Epoch: 10 [  9000/60000 (15%)]\tLoss: 0.084661\n",
      "Train Epoch: 10 [ 10000/60000 (17%)]\tLoss: 0.011669\n",
      "Train Epoch: 10 [ 11000/60000 (18%)]\tLoss: 0.089833\n",
      "Train Epoch: 10 [ 12000/60000 (20%)]\tLoss: 0.037012\n",
      "Train Epoch: 10 [ 13000/60000 (22%)]\tLoss: 0.063439\n",
      "Train Epoch: 10 [ 14000/60000 (23%)]\tLoss: 0.036947\n",
      "Train Epoch: 10 [ 15000/60000 (25%)]\tLoss: 0.036182\n",
      "Train Epoch: 10 [ 16000/60000 (27%)]\tLoss: 0.023898\n",
      "Train Epoch: 10 [ 17000/60000 (28%)]\tLoss: 0.025261\n",
      "Train Epoch: 10 [ 18000/60000 (30%)]\tLoss: 0.087419\n",
      "Train Epoch: 10 [ 19000/60000 (32%)]\tLoss: 0.032159\n",
      "Train Epoch: 10 [ 20000/60000 (33%)]\tLoss: 0.093053\n",
      "Train Epoch: 10 [ 21000/60000 (35%)]\tLoss: 0.077847\n",
      "Train Epoch: 10 [ 22000/60000 (37%)]\tLoss: 0.073575\n",
      "Train Epoch: 10 [ 23000/60000 (38%)]\tLoss: 0.055870\n",
      "Train Epoch: 10 [ 24000/60000 (40%)]\tLoss: 0.026203\n",
      "Train Epoch: 10 [ 25000/60000 (42%)]\tLoss: 0.040771\n",
      "Train Epoch: 10 [ 26000/60000 (43%)]\tLoss: 0.078272\n",
      "Train Epoch: 10 [ 27000/60000 (45%)]\tLoss: 0.023244\n",
      "Train Epoch: 10 [ 28000/60000 (47%)]\tLoss: 0.027404\n",
      "Train Epoch: 10 [ 29000/60000 (48%)]\tLoss: 0.097743\n",
      "Train Epoch: 10 [ 30000/60000 (50%)]\tLoss: 0.042784\n",
      "Train Epoch: 10 [ 31000/60000 (52%)]\tLoss: 0.031440\n",
      "Train Epoch: 10 [ 32000/60000 (53%)]\tLoss: 0.178223\n",
      "Train Epoch: 10 [ 33000/60000 (55%)]\tLoss: 0.053032\n",
      "Train Epoch: 10 [ 34000/60000 (57%)]\tLoss: 0.112622\n",
      "Train Epoch: 10 [ 35000/60000 (58%)]\tLoss: 0.056328\n",
      "Train Epoch: 10 [ 36000/60000 (60%)]\tLoss: 0.044374\n",
      "Train Epoch: 10 [ 37000/60000 (62%)]\tLoss: 0.119955\n",
      "Train Epoch: 10 [ 38000/60000 (63%)]\tLoss: 0.097507\n",
      "Train Epoch: 10 [ 39000/60000 (65%)]\tLoss: 0.126272\n",
      "Train Epoch: 10 [ 40000/60000 (67%)]\tLoss: 0.020986\n",
      "Train Epoch: 10 [ 41000/60000 (68%)]\tLoss: 0.077009\n",
      "Train Epoch: 10 [ 42000/60000 (70%)]\tLoss: 0.056693\n",
      "Train Epoch: 10 [ 43000/60000 (72%)]\tLoss: 0.064290\n",
      "Train Epoch: 10 [ 44000/60000 (73%)]\tLoss: 0.072656\n",
      "Train Epoch: 10 [ 45000/60000 (75%)]\tLoss: 0.100405\n",
      "Train Epoch: 10 [ 46000/60000 (77%)]\tLoss: 0.046199\n",
      "Train Epoch: 10 [ 47000/60000 (78%)]\tLoss: 0.042166\n",
      "Train Epoch: 10 [ 48000/60000 (80%)]\tLoss: 0.023374\n",
      "Train Epoch: 10 [ 49000/60000 (82%)]\tLoss: 0.041308\n",
      "Train Epoch: 10 [ 50000/60000 (83%)]\tLoss: 0.072379\n",
      "Train Epoch: 10 [ 51000/60000 (85%)]\tLoss: 0.091020\n",
      "Train Epoch: 10 [ 52000/60000 (87%)]\tLoss: 0.060297\n",
      "Train Epoch: 10 [ 53000/60000 (88%)]\tLoss: 0.011118\n",
      "Train Epoch: 10 [ 54000/60000 (90%)]\tLoss: 0.045228\n",
      "Train Epoch: 10 [ 55000/60000 (92%)]\tLoss: 0.096735\n",
      "Train Epoch: 10 [ 56000/60000 (93%)]\tLoss: 0.031987\n",
      "Train Epoch: 10 [ 57000/60000 (95%)]\tLoss: 0.073158\n",
      "Train Epoch: 10 [ 58000/60000 (97%)]\tLoss: 0.043454\n",
      "Train Epoch: 10 [ 59000/60000 (98%)]\tLoss: 0.043139\n",
      "Train Epoch: 10 [ 60000/60000 (100%)]\tLoss: 0.057760\n",
      "\n",
      "Test Set: Avg. loss: 0.0523, Accuracy: 9826/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(train_counter))\n",
    "print(len(train_losses))\n",
    "print(len(test_counter))\n",
    "print(len(test_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw loss graph.\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check on examples.\n",
    "examples = enumerate(test_loader)\n",
    "example_batch_id, (example_images, example_labels) = next(examples)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = network(example_images)\n",
    "    \n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_images[i][0], cmap='gray')\n",
    "    plt.title(\"Prediction: {}\".format(output.data.max(1, keepdim=True)[1][i].item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Continued Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [  1000/60000 (2%)]\tLoss: 0.030951\n",
      "Train Epoch: 11 [  2000/60000 (3%)]\tLoss: 0.072313\n",
      "Train Epoch: 11 [  3000/60000 (5%)]\tLoss: 0.062763\n",
      "Train Epoch: 11 [  4000/60000 (7%)]\tLoss: 0.027835\n",
      "Train Epoch: 11 [  5000/60000 (8%)]\tLoss: 0.058666\n",
      "Train Epoch: 11 [  6000/60000 (10%)]\tLoss: 0.074312\n",
      "Train Epoch: 11 [  7000/60000 (12%)]\tLoss: 0.038405\n",
      "Train Epoch: 11 [  8000/60000 (13%)]\tLoss: 0.011898\n",
      "Train Epoch: 11 [  9000/60000 (15%)]\tLoss: 0.074915\n",
      "Train Epoch: 11 [ 10000/60000 (17%)]\tLoss: 0.082413\n",
      "Train Epoch: 11 [ 11000/60000 (18%)]\tLoss: 0.057160\n",
      "Train Epoch: 11 [ 12000/60000 (20%)]\tLoss: 0.066005\n",
      "Train Epoch: 11 [ 13000/60000 (22%)]\tLoss: 0.029492\n",
      "Train Epoch: 11 [ 14000/60000 (23%)]\tLoss: 0.086791\n",
      "Train Epoch: 11 [ 15000/60000 (25%)]\tLoss: 0.063082\n",
      "Train Epoch: 11 [ 16000/60000 (27%)]\tLoss: 0.015893\n",
      "Train Epoch: 11 [ 17000/60000 (28%)]\tLoss: 0.100251\n",
      "Train Epoch: 11 [ 18000/60000 (30%)]\tLoss: 0.017891\n",
      "Train Epoch: 11 [ 19000/60000 (32%)]\tLoss: 0.032422\n",
      "Train Epoch: 11 [ 20000/60000 (33%)]\tLoss: 0.072820\n",
      "Train Epoch: 11 [ 21000/60000 (35%)]\tLoss: 0.035004\n",
      "Train Epoch: 11 [ 22000/60000 (37%)]\tLoss: 0.065161\n",
      "Train Epoch: 11 [ 23000/60000 (38%)]\tLoss: 0.079000\n",
      "Train Epoch: 11 [ 24000/60000 (40%)]\tLoss: 0.071399\n",
      "Train Epoch: 11 [ 25000/60000 (42%)]\tLoss: 0.062202\n",
      "Train Epoch: 11 [ 26000/60000 (43%)]\tLoss: 0.036674\n",
      "Train Epoch: 11 [ 27000/60000 (45%)]\tLoss: 0.181241\n",
      "Train Epoch: 11 [ 28000/60000 (47%)]\tLoss: 0.090355\n",
      "Train Epoch: 11 [ 29000/60000 (48%)]\tLoss: 0.058164\n",
      "Train Epoch: 11 [ 30000/60000 (50%)]\tLoss: 0.010698\n",
      "Train Epoch: 11 [ 31000/60000 (52%)]\tLoss: 0.039758\n",
      "Train Epoch: 11 [ 32000/60000 (53%)]\tLoss: 0.015523\n",
      "Train Epoch: 11 [ 33000/60000 (55%)]\tLoss: 0.031287\n",
      "Train Epoch: 11 [ 34000/60000 (57%)]\tLoss: 0.028541\n",
      "Train Epoch: 11 [ 35000/60000 (58%)]\tLoss: 0.025324\n",
      "Train Epoch: 11 [ 36000/60000 (60%)]\tLoss: 0.078787\n",
      "Train Epoch: 11 [ 37000/60000 (62%)]\tLoss: 0.008155\n",
      "Train Epoch: 11 [ 38000/60000 (63%)]\tLoss: 0.124969\n",
      "Train Epoch: 11 [ 39000/60000 (65%)]\tLoss: 0.071529\n",
      "Train Epoch: 11 [ 40000/60000 (67%)]\tLoss: 0.029449\n",
      "Train Epoch: 11 [ 41000/60000 (68%)]\tLoss: 0.040891\n",
      "Train Epoch: 11 [ 42000/60000 (70%)]\tLoss: 0.081215\n",
      "Train Epoch: 11 [ 43000/60000 (72%)]\tLoss: 0.056169\n",
      "Train Epoch: 11 [ 44000/60000 (73%)]\tLoss: 0.118071\n",
      "Train Epoch: 11 [ 45000/60000 (75%)]\tLoss: 0.123043\n",
      "Train Epoch: 11 [ 46000/60000 (77%)]\tLoss: 0.016843\n",
      "Train Epoch: 11 [ 47000/60000 (78%)]\tLoss: 0.044469\n",
      "Train Epoch: 11 [ 48000/60000 (80%)]\tLoss: 0.076065\n",
      "Train Epoch: 11 [ 49000/60000 (82%)]\tLoss: 0.028508\n",
      "Train Epoch: 11 [ 50000/60000 (83%)]\tLoss: 0.066642\n",
      "Train Epoch: 11 [ 51000/60000 (85%)]\tLoss: 0.021902\n",
      "Train Epoch: 11 [ 52000/60000 (87%)]\tLoss: 0.028681\n",
      "Train Epoch: 11 [ 53000/60000 (88%)]\tLoss: 0.059193\n",
      "Train Epoch: 11 [ 54000/60000 (90%)]\tLoss: 0.056098\n",
      "Train Epoch: 11 [ 55000/60000 (92%)]\tLoss: 0.036195\n",
      "Train Epoch: 11 [ 56000/60000 (93%)]\tLoss: 0.025247\n",
      "Train Epoch: 11 [ 57000/60000 (95%)]\tLoss: 0.099797\n",
      "Train Epoch: 11 [ 58000/60000 (97%)]\tLoss: 0.044717\n",
      "Train Epoch: 11 [ 59000/60000 (98%)]\tLoss: 0.043704\n",
      "Train Epoch: 11 [ 60000/60000 (100%)]\tLoss: 0.033038\n",
      "\n",
      "Test Set: Avg. loss: 0.0475, Accuracy: 9836/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [  1000/60000 (2%)]\tLoss: 0.037725\n",
      "Train Epoch: 12 [  2000/60000 (3%)]\tLoss: 0.100615\n",
      "Train Epoch: 12 [  3000/60000 (5%)]\tLoss: 0.048683\n",
      "Train Epoch: 12 [  4000/60000 (7%)]\tLoss: 0.039711\n",
      "Train Epoch: 12 [  5000/60000 (8%)]\tLoss: 0.065568\n",
      "Train Epoch: 12 [  6000/60000 (10%)]\tLoss: 0.009761\n",
      "Train Epoch: 12 [  7000/60000 (12%)]\tLoss: 0.079616\n",
      "Train Epoch: 12 [  8000/60000 (13%)]\tLoss: 0.032490\n",
      "Train Epoch: 12 [  9000/60000 (15%)]\tLoss: 0.061690\n",
      "Train Epoch: 12 [ 10000/60000 (17%)]\tLoss: 0.030388\n",
      "Train Epoch: 12 [ 11000/60000 (18%)]\tLoss: 0.075683\n",
      "Train Epoch: 12 [ 12000/60000 (20%)]\tLoss: 0.069658\n",
      "Train Epoch: 12 [ 13000/60000 (22%)]\tLoss: 0.017664\n",
      "Train Epoch: 12 [ 14000/60000 (23%)]\tLoss: 0.041228\n",
      "Train Epoch: 12 [ 15000/60000 (25%)]\tLoss: 0.012371\n",
      "Train Epoch: 12 [ 16000/60000 (27%)]\tLoss: 0.038464\n",
      "Train Epoch: 12 [ 17000/60000 (28%)]\tLoss: 0.098600\n",
      "Train Epoch: 12 [ 18000/60000 (30%)]\tLoss: 0.035257\n",
      "Train Epoch: 12 [ 19000/60000 (32%)]\tLoss: 0.047279\n",
      "Train Epoch: 12 [ 20000/60000 (33%)]\tLoss: 0.010955\n",
      "Train Epoch: 12 [ 21000/60000 (35%)]\tLoss: 0.035062\n",
      "Train Epoch: 12 [ 22000/60000 (37%)]\tLoss: 0.059953\n",
      "Train Epoch: 12 [ 23000/60000 (38%)]\tLoss: 0.079018\n",
      "Train Epoch: 12 [ 24000/60000 (40%)]\tLoss: 0.021070\n",
      "Train Epoch: 12 [ 25000/60000 (42%)]\tLoss: 0.016209\n",
      "Train Epoch: 12 [ 26000/60000 (43%)]\tLoss: 0.085479\n",
      "Train Epoch: 12 [ 27000/60000 (45%)]\tLoss: 0.032307\n",
      "Train Epoch: 12 [ 28000/60000 (47%)]\tLoss: 0.037299\n",
      "Train Epoch: 12 [ 29000/60000 (48%)]\tLoss: 0.040069\n",
      "Train Epoch: 12 [ 30000/60000 (50%)]\tLoss: 0.050307\n",
      "Train Epoch: 12 [ 31000/60000 (52%)]\tLoss: 0.042572\n",
      "Train Epoch: 12 [ 32000/60000 (53%)]\tLoss: 0.013731\n",
      "Train Epoch: 12 [ 33000/60000 (55%)]\tLoss: 0.019792\n",
      "Train Epoch: 12 [ 34000/60000 (57%)]\tLoss: 0.072758\n",
      "Train Epoch: 12 [ 35000/60000 (58%)]\tLoss: 0.059094\n",
      "Train Epoch: 12 [ 36000/60000 (60%)]\tLoss: 0.055811\n",
      "Train Epoch: 12 [ 37000/60000 (62%)]\tLoss: 0.096239\n",
      "Train Epoch: 12 [ 38000/60000 (63%)]\tLoss: 0.037491\n",
      "Train Epoch: 12 [ 39000/60000 (65%)]\tLoss: 0.019322\n",
      "Train Epoch: 12 [ 40000/60000 (67%)]\tLoss: 0.090064\n",
      "Train Epoch: 12 [ 41000/60000 (68%)]\tLoss: 0.019623\n",
      "Train Epoch: 12 [ 42000/60000 (70%)]\tLoss: 0.062953\n",
      "Train Epoch: 12 [ 43000/60000 (72%)]\tLoss: 0.020085\n",
      "Train Epoch: 12 [ 44000/60000 (73%)]\tLoss: 0.114092\n",
      "Train Epoch: 12 [ 45000/60000 (75%)]\tLoss: 0.025202\n",
      "Train Epoch: 12 [ 46000/60000 (77%)]\tLoss: 0.011409\n",
      "Train Epoch: 12 [ 47000/60000 (78%)]\tLoss: 0.044679\n",
      "Train Epoch: 12 [ 48000/60000 (80%)]\tLoss: 0.049759\n",
      "Train Epoch: 12 [ 49000/60000 (82%)]\tLoss: 0.013080\n",
      "Train Epoch: 12 [ 50000/60000 (83%)]\tLoss: 0.062075\n",
      "Train Epoch: 12 [ 51000/60000 (85%)]\tLoss: 0.052724\n",
      "Train Epoch: 12 [ 52000/60000 (87%)]\tLoss: 0.094892\n",
      "Train Epoch: 12 [ 53000/60000 (88%)]\tLoss: 0.009143\n",
      "Train Epoch: 12 [ 54000/60000 (90%)]\tLoss: 0.058565\n",
      "Train Epoch: 12 [ 55000/60000 (92%)]\tLoss: 0.012571\n",
      "Train Epoch: 12 [ 56000/60000 (93%)]\tLoss: 0.044206\n",
      "Train Epoch: 12 [ 57000/60000 (95%)]\tLoss: 0.051798\n",
      "Train Epoch: 12 [ 58000/60000 (97%)]\tLoss: 0.049186\n",
      "Train Epoch: 12 [ 59000/60000 (98%)]\tLoss: 0.014750\n",
      "Train Epoch: 12 [ 60000/60000 (100%)]\tLoss: 0.055173\n",
      "\n",
      "Test Set: Avg. loss: 0.0460, Accuracy: 9851/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [  1000/60000 (2%)]\tLoss: 0.087345\n",
      "Train Epoch: 13 [  2000/60000 (3%)]\tLoss: 0.014956\n",
      "Train Epoch: 13 [  3000/60000 (5%)]\tLoss: 0.041086\n",
      "Train Epoch: 13 [  4000/60000 (7%)]\tLoss: 0.108824\n",
      "Train Epoch: 13 [  5000/60000 (8%)]\tLoss: 0.043377\n",
      "Train Epoch: 13 [  6000/60000 (10%)]\tLoss: 0.037512\n",
      "Train Epoch: 13 [  7000/60000 (12%)]\tLoss: 0.075107\n",
      "Train Epoch: 13 [  8000/60000 (13%)]\tLoss: 0.020460\n",
      "Train Epoch: 13 [  9000/60000 (15%)]\tLoss: 0.043536\n",
      "Train Epoch: 13 [ 10000/60000 (17%)]\tLoss: 0.112027\n",
      "Train Epoch: 13 [ 11000/60000 (18%)]\tLoss: 0.075844\n",
      "Train Epoch: 13 [ 12000/60000 (20%)]\tLoss: 0.034415\n",
      "Train Epoch: 13 [ 13000/60000 (22%)]\tLoss: 0.160565\n",
      "Train Epoch: 13 [ 14000/60000 (23%)]\tLoss: 0.016462\n",
      "Train Epoch: 13 [ 15000/60000 (25%)]\tLoss: 0.038271\n",
      "Train Epoch: 13 [ 16000/60000 (27%)]\tLoss: 0.021449\n",
      "Train Epoch: 13 [ 17000/60000 (28%)]\tLoss: 0.030109\n",
      "Train Epoch: 13 [ 18000/60000 (30%)]\tLoss: 0.027304\n",
      "Train Epoch: 13 [ 19000/60000 (32%)]\tLoss: 0.031673\n",
      "Train Epoch: 13 [ 20000/60000 (33%)]\tLoss: 0.028264\n",
      "Train Epoch: 13 [ 21000/60000 (35%)]\tLoss: 0.095810\n",
      "Train Epoch: 13 [ 22000/60000 (37%)]\tLoss: 0.063028\n",
      "Train Epoch: 13 [ 23000/60000 (38%)]\tLoss: 0.065919\n",
      "Train Epoch: 13 [ 24000/60000 (40%)]\tLoss: 0.054177\n",
      "Train Epoch: 13 [ 25000/60000 (42%)]\tLoss: 0.011450\n",
      "Train Epoch: 13 [ 26000/60000 (43%)]\tLoss: 0.008767\n",
      "Train Epoch: 13 [ 27000/60000 (45%)]\tLoss: 0.012757\n",
      "Train Epoch: 13 [ 28000/60000 (47%)]\tLoss: 0.062814\n",
      "Train Epoch: 13 [ 29000/60000 (48%)]\tLoss: 0.026895\n",
      "Train Epoch: 13 [ 30000/60000 (50%)]\tLoss: 0.020003\n",
      "Train Epoch: 13 [ 31000/60000 (52%)]\tLoss: 0.026949\n",
      "Train Epoch: 13 [ 32000/60000 (53%)]\tLoss: 0.008374\n",
      "Train Epoch: 13 [ 33000/60000 (55%)]\tLoss: 0.048079\n",
      "Train Epoch: 13 [ 34000/60000 (57%)]\tLoss: 0.015837\n",
      "Train Epoch: 13 [ 35000/60000 (58%)]\tLoss: 0.087668\n",
      "Train Epoch: 13 [ 36000/60000 (60%)]\tLoss: 0.042425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [ 37000/60000 (62%)]\tLoss: 0.022586\n",
      "Train Epoch: 13 [ 38000/60000 (63%)]\tLoss: 0.027360\n",
      "Train Epoch: 13 [ 39000/60000 (65%)]\tLoss: 0.057533\n",
      "Train Epoch: 13 [ 40000/60000 (67%)]\tLoss: 0.075353\n",
      "Train Epoch: 13 [ 41000/60000 (68%)]\tLoss: 0.054756\n",
      "Train Epoch: 13 [ 42000/60000 (70%)]\tLoss: 0.021287\n",
      "Train Epoch: 13 [ 43000/60000 (72%)]\tLoss: 0.012287\n",
      "Train Epoch: 13 [ 44000/60000 (73%)]\tLoss: 0.040624\n",
      "Train Epoch: 13 [ 45000/60000 (75%)]\tLoss: 0.104697\n",
      "Train Epoch: 13 [ 46000/60000 (77%)]\tLoss: 0.111900\n",
      "Train Epoch: 13 [ 47000/60000 (78%)]\tLoss: 0.007161\n",
      "Train Epoch: 13 [ 48000/60000 (80%)]\tLoss: 0.033801\n",
      "Train Epoch: 13 [ 49000/60000 (82%)]\tLoss: 0.117671\n",
      "Train Epoch: 13 [ 50000/60000 (83%)]\tLoss: 0.031830\n",
      "Train Epoch: 13 [ 51000/60000 (85%)]\tLoss: 0.015067\n",
      "Train Epoch: 13 [ 52000/60000 (87%)]\tLoss: 0.029644\n",
      "Train Epoch: 13 [ 53000/60000 (88%)]\tLoss: 0.069340\n",
      "Train Epoch: 13 [ 54000/60000 (90%)]\tLoss: 0.031790\n",
      "Train Epoch: 13 [ 55000/60000 (92%)]\tLoss: 0.096494\n",
      "Train Epoch: 13 [ 56000/60000 (93%)]\tLoss: 0.124524\n",
      "Train Epoch: 13 [ 57000/60000 (95%)]\tLoss: 0.090045\n",
      "Train Epoch: 13 [ 58000/60000 (97%)]\tLoss: 0.050716\n",
      "Train Epoch: 13 [ 59000/60000 (98%)]\tLoss: 0.153121\n",
      "Train Epoch: 13 [ 60000/60000 (100%)]\tLoss: 0.071911\n",
      "\n",
      "Test Set: Avg. loss: 0.0412, Accuracy: 9858/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [  1000/60000 (2%)]\tLoss: 0.019724\n",
      "Train Epoch: 14 [  2000/60000 (3%)]\tLoss: 0.037686\n",
      "Train Epoch: 14 [  3000/60000 (5%)]\tLoss: 0.060275\n",
      "Train Epoch: 14 [  4000/60000 (7%)]\tLoss: 0.062613\n",
      "Train Epoch: 14 [  5000/60000 (8%)]\tLoss: 0.032790\n",
      "Train Epoch: 14 [  6000/60000 (10%)]\tLoss: 0.094564\n",
      "Train Epoch: 14 [  7000/60000 (12%)]\tLoss: 0.068757\n",
      "Train Epoch: 14 [  8000/60000 (13%)]\tLoss: 0.034596\n",
      "Train Epoch: 14 [  9000/60000 (15%)]\tLoss: 0.080360\n",
      "Train Epoch: 14 [ 10000/60000 (17%)]\tLoss: 0.008305\n",
      "Train Epoch: 14 [ 11000/60000 (18%)]\tLoss: 0.052878\n",
      "Train Epoch: 14 [ 12000/60000 (20%)]\tLoss: 0.022040\n",
      "Train Epoch: 14 [ 13000/60000 (22%)]\tLoss: 0.047742\n",
      "Train Epoch: 14 [ 14000/60000 (23%)]\tLoss: 0.022041\n",
      "Train Epoch: 14 [ 15000/60000 (25%)]\tLoss: 0.088011\n",
      "Train Epoch: 14 [ 16000/60000 (27%)]\tLoss: 0.024524\n",
      "Train Epoch: 14 [ 17000/60000 (28%)]\tLoss: 0.040963\n",
      "Train Epoch: 14 [ 18000/60000 (30%)]\tLoss: 0.019429\n",
      "Train Epoch: 14 [ 19000/60000 (32%)]\tLoss: 0.041295\n",
      "Train Epoch: 14 [ 20000/60000 (33%)]\tLoss: 0.032721\n",
      "Train Epoch: 14 [ 21000/60000 (35%)]\tLoss: 0.014952\n",
      "Train Epoch: 14 [ 22000/60000 (37%)]\tLoss: 0.081046\n",
      "Train Epoch: 14 [ 23000/60000 (38%)]\tLoss: 0.101512\n",
      "Train Epoch: 14 [ 24000/60000 (40%)]\tLoss: 0.006115\n",
      "Train Epoch: 14 [ 25000/60000 (42%)]\tLoss: 0.102353\n",
      "Train Epoch: 14 [ 26000/60000 (43%)]\tLoss: 0.080722\n",
      "Train Epoch: 14 [ 27000/60000 (45%)]\tLoss: 0.024858\n",
      "Train Epoch: 14 [ 28000/60000 (47%)]\tLoss: 0.011782\n",
      "Train Epoch: 14 [ 29000/60000 (48%)]\tLoss: 0.071362\n",
      "Train Epoch: 14 [ 30000/60000 (50%)]\tLoss: 0.021493\n",
      "Train Epoch: 14 [ 31000/60000 (52%)]\tLoss: 0.040396\n",
      "Train Epoch: 14 [ 32000/60000 (53%)]\tLoss: 0.029185\n",
      "Train Epoch: 14 [ 33000/60000 (55%)]\tLoss: 0.015946\n",
      "Train Epoch: 14 [ 34000/60000 (57%)]\tLoss: 0.040004\n",
      "Train Epoch: 14 [ 35000/60000 (58%)]\tLoss: 0.014350\n",
      "Train Epoch: 14 [ 36000/60000 (60%)]\tLoss: 0.036295\n",
      "Train Epoch: 14 [ 37000/60000 (62%)]\tLoss: 0.024711\n",
      "Train Epoch: 14 [ 38000/60000 (63%)]\tLoss: 0.003541\n",
      "Train Epoch: 14 [ 39000/60000 (65%)]\tLoss: 0.061652\n",
      "Train Epoch: 14 [ 40000/60000 (67%)]\tLoss: 0.051688\n",
      "Train Epoch: 14 [ 41000/60000 (68%)]\tLoss: 0.032000\n",
      "Train Epoch: 14 [ 42000/60000 (70%)]\tLoss: 0.080953\n",
      "Train Epoch: 14 [ 43000/60000 (72%)]\tLoss: 0.035689\n",
      "Train Epoch: 14 [ 44000/60000 (73%)]\tLoss: 0.027140\n",
      "Train Epoch: 14 [ 45000/60000 (75%)]\tLoss: 0.040651\n",
      "Train Epoch: 14 [ 46000/60000 (77%)]\tLoss: 0.042577\n",
      "Train Epoch: 14 [ 47000/60000 (78%)]\tLoss: 0.039567\n",
      "Train Epoch: 14 [ 48000/60000 (80%)]\tLoss: 0.010963\n",
      "Train Epoch: 14 [ 49000/60000 (82%)]\tLoss: 0.044831\n",
      "Train Epoch: 14 [ 50000/60000 (83%)]\tLoss: 0.043440\n",
      "Train Epoch: 14 [ 51000/60000 (85%)]\tLoss: 0.065985\n",
      "Train Epoch: 14 [ 52000/60000 (87%)]\tLoss: 0.034344\n",
      "Train Epoch: 14 [ 53000/60000 (88%)]\tLoss: 0.008149\n",
      "Train Epoch: 14 [ 54000/60000 (90%)]\tLoss: 0.014750\n",
      "Train Epoch: 14 [ 55000/60000 (92%)]\tLoss: 0.021229\n",
      "Train Epoch: 14 [ 56000/60000 (93%)]\tLoss: 0.094434\n",
      "Train Epoch: 14 [ 57000/60000 (95%)]\tLoss: 0.106526\n",
      "Train Epoch: 14 [ 58000/60000 (97%)]\tLoss: 0.176788\n",
      "Train Epoch: 14 [ 59000/60000 (98%)]\tLoss: 0.060399\n",
      "Train Epoch: 14 [ 60000/60000 (100%)]\tLoss: 0.043667\n",
      "\n",
      "Test Set: Avg. loss: 0.0402, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [  1000/60000 (2%)]\tLoss: 0.023684\n",
      "Train Epoch: 15 [  2000/60000 (3%)]\tLoss: 0.064069\n",
      "Train Epoch: 15 [  3000/60000 (5%)]\tLoss: 0.020391\n",
      "Train Epoch: 15 [  4000/60000 (7%)]\tLoss: 0.070928\n",
      "Train Epoch: 15 [  5000/60000 (8%)]\tLoss: 0.048213\n",
      "Train Epoch: 15 [  6000/60000 (10%)]\tLoss: 0.077806\n",
      "Train Epoch: 15 [  7000/60000 (12%)]\tLoss: 0.037955\n",
      "Train Epoch: 15 [  8000/60000 (13%)]\tLoss: 0.006206\n",
      "Train Epoch: 15 [  9000/60000 (15%)]\tLoss: 0.171226\n",
      "Train Epoch: 15 [ 10000/60000 (17%)]\tLoss: 0.016176\n",
      "Train Epoch: 15 [ 11000/60000 (18%)]\tLoss: 0.040812\n",
      "Train Epoch: 15 [ 12000/60000 (20%)]\tLoss: 0.121793\n",
      "Train Epoch: 15 [ 13000/60000 (22%)]\tLoss: 0.025047\n",
      "Train Epoch: 15 [ 14000/60000 (23%)]\tLoss: 0.015279\n",
      "Train Epoch: 15 [ 15000/60000 (25%)]\tLoss: 0.036374\n",
      "Train Epoch: 15 [ 16000/60000 (27%)]\tLoss: 0.043108\n",
      "Train Epoch: 15 [ 17000/60000 (28%)]\tLoss: 0.019711\n",
      "Train Epoch: 15 [ 18000/60000 (30%)]\tLoss: 0.104332\n",
      "Train Epoch: 15 [ 19000/60000 (32%)]\tLoss: 0.025895\n",
      "Train Epoch: 15 [ 20000/60000 (33%)]\tLoss: 0.027277\n",
      "Train Epoch: 15 [ 21000/60000 (35%)]\tLoss: 0.037907\n",
      "Train Epoch: 15 [ 22000/60000 (37%)]\tLoss: 0.078075\n",
      "Train Epoch: 15 [ 23000/60000 (38%)]\tLoss: 0.067883\n",
      "Train Epoch: 15 [ 24000/60000 (40%)]\tLoss: 0.036710\n",
      "Train Epoch: 15 [ 25000/60000 (42%)]\tLoss: 0.039091\n",
      "Train Epoch: 15 [ 26000/60000 (43%)]\tLoss: 0.041282\n",
      "Train Epoch: 15 [ 27000/60000 (45%)]\tLoss: 0.036832\n",
      "Train Epoch: 15 [ 28000/60000 (47%)]\tLoss: 0.027562\n",
      "Train Epoch: 15 [ 29000/60000 (48%)]\tLoss: 0.016203\n",
      "Train Epoch: 15 [ 30000/60000 (50%)]\tLoss: 0.022579\n",
      "Train Epoch: 15 [ 31000/60000 (52%)]\tLoss: 0.036413\n",
      "Train Epoch: 15 [ 32000/60000 (53%)]\tLoss: 0.059568\n",
      "Train Epoch: 15 [ 33000/60000 (55%)]\tLoss: 0.071678\n",
      "Train Epoch: 15 [ 34000/60000 (57%)]\tLoss: 0.021424\n",
      "Train Epoch: 15 [ 35000/60000 (58%)]\tLoss: 0.029870\n",
      "Train Epoch: 15 [ 36000/60000 (60%)]\tLoss: 0.034014\n",
      "Train Epoch: 15 [ 37000/60000 (62%)]\tLoss: 0.031680\n",
      "Train Epoch: 15 [ 38000/60000 (63%)]\tLoss: 0.084207\n",
      "Train Epoch: 15 [ 39000/60000 (65%)]\tLoss: 0.027511\n",
      "Train Epoch: 15 [ 40000/60000 (67%)]\tLoss: 0.020079\n",
      "Train Epoch: 15 [ 41000/60000 (68%)]\tLoss: 0.062487\n",
      "Train Epoch: 15 [ 42000/60000 (70%)]\tLoss: 0.021988\n",
      "Train Epoch: 15 [ 43000/60000 (72%)]\tLoss: 0.021878\n",
      "Train Epoch: 15 [ 44000/60000 (73%)]\tLoss: 0.065082\n",
      "Train Epoch: 15 [ 45000/60000 (75%)]\tLoss: 0.082378\n",
      "Train Epoch: 15 [ 46000/60000 (77%)]\tLoss: 0.037493\n",
      "Train Epoch: 15 [ 47000/60000 (78%)]\tLoss: 0.029875\n",
      "Train Epoch: 15 [ 48000/60000 (80%)]\tLoss: 0.010431\n",
      "Train Epoch: 15 [ 49000/60000 (82%)]\tLoss: 0.037622\n",
      "Train Epoch: 15 [ 50000/60000 (83%)]\tLoss: 0.010921\n",
      "Train Epoch: 15 [ 51000/60000 (85%)]\tLoss: 0.055024\n",
      "Train Epoch: 15 [ 52000/60000 (87%)]\tLoss: 0.011819\n",
      "Train Epoch: 15 [ 53000/60000 (88%)]\tLoss: 0.025030\n",
      "Train Epoch: 15 [ 54000/60000 (90%)]\tLoss: 0.124897\n",
      "Train Epoch: 15 [ 55000/60000 (92%)]\tLoss: 0.067422\n",
      "Train Epoch: 15 [ 56000/60000 (93%)]\tLoss: 0.013595\n",
      "Train Epoch: 15 [ 57000/60000 (95%)]\tLoss: 0.016305\n",
      "Train Epoch: 15 [ 58000/60000 (97%)]\tLoss: 0.093954\n",
      "Train Epoch: 15 [ 59000/60000 (98%)]\tLoss: 0.044269\n",
      "Train Epoch: 15 [ 60000/60000 (100%)]\tLoss: 0.054746\n",
      "\n",
      "Test Set: Avg. loss: 0.0422, Accuracy: 9862/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [  1000/60000 (2%)]\tLoss: 0.050788\n",
      "Train Epoch: 16 [  2000/60000 (3%)]\tLoss: 0.017274\n",
      "Train Epoch: 16 [  3000/60000 (5%)]\tLoss: 0.031114\n",
      "Train Epoch: 16 [  4000/60000 (7%)]\tLoss: 0.070600\n",
      "Train Epoch: 16 [  5000/60000 (8%)]\tLoss: 0.014346\n",
      "Train Epoch: 16 [  6000/60000 (10%)]\tLoss: 0.036849\n",
      "Train Epoch: 16 [  7000/60000 (12%)]\tLoss: 0.015702\n",
      "Train Epoch: 16 [  8000/60000 (13%)]\tLoss: 0.027694\n",
      "Train Epoch: 16 [  9000/60000 (15%)]\tLoss: 0.043541\n",
      "Train Epoch: 16 [ 10000/60000 (17%)]\tLoss: 0.019974\n",
      "Train Epoch: 16 [ 11000/60000 (18%)]\tLoss: 0.081495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [ 12000/60000 (20%)]\tLoss: 0.074609\n",
      "Train Epoch: 16 [ 13000/60000 (22%)]\tLoss: 0.043837\n",
      "Train Epoch: 16 [ 14000/60000 (23%)]\tLoss: 0.037694\n",
      "Train Epoch: 16 [ 15000/60000 (25%)]\tLoss: 0.037445\n",
      "Train Epoch: 16 [ 16000/60000 (27%)]\tLoss: 0.015861\n",
      "Train Epoch: 16 [ 17000/60000 (28%)]\tLoss: 0.021194\n",
      "Train Epoch: 16 [ 18000/60000 (30%)]\tLoss: 0.070763\n",
      "Train Epoch: 16 [ 19000/60000 (32%)]\tLoss: 0.046929\n",
      "Train Epoch: 16 [ 20000/60000 (33%)]\tLoss: 0.025831\n",
      "Train Epoch: 16 [ 21000/60000 (35%)]\tLoss: 0.015320\n",
      "Train Epoch: 16 [ 22000/60000 (37%)]\tLoss: 0.045131\n",
      "Train Epoch: 16 [ 23000/60000 (38%)]\tLoss: 0.042942\n",
      "Train Epoch: 16 [ 24000/60000 (40%)]\tLoss: 0.157281\n",
      "Train Epoch: 16 [ 25000/60000 (42%)]\tLoss: 0.042733\n",
      "Train Epoch: 16 [ 26000/60000 (43%)]\tLoss: 0.011347\n",
      "Train Epoch: 16 [ 27000/60000 (45%)]\tLoss: 0.010161\n",
      "Train Epoch: 16 [ 28000/60000 (47%)]\tLoss: 0.019352\n",
      "Train Epoch: 16 [ 29000/60000 (48%)]\tLoss: 0.015515\n",
      "Train Epoch: 16 [ 30000/60000 (50%)]\tLoss: 0.091720\n",
      "Train Epoch: 16 [ 31000/60000 (52%)]\tLoss: 0.028210\n",
      "Train Epoch: 16 [ 32000/60000 (53%)]\tLoss: 0.075808\n",
      "Train Epoch: 16 [ 33000/60000 (55%)]\tLoss: 0.024082\n",
      "Train Epoch: 16 [ 34000/60000 (57%)]\tLoss: 0.079128\n",
      "Train Epoch: 16 [ 35000/60000 (58%)]\tLoss: 0.017177\n",
      "Train Epoch: 16 [ 36000/60000 (60%)]\tLoss: 0.035578\n",
      "Train Epoch: 16 [ 37000/60000 (62%)]\tLoss: 0.012172\n",
      "Train Epoch: 16 [ 38000/60000 (63%)]\tLoss: 0.036288\n",
      "Train Epoch: 16 [ 39000/60000 (65%)]\tLoss: 0.021311\n",
      "Train Epoch: 16 [ 40000/60000 (67%)]\tLoss: 0.010913\n",
      "Train Epoch: 16 [ 41000/60000 (68%)]\tLoss: 0.017253\n",
      "Train Epoch: 16 [ 42000/60000 (70%)]\tLoss: 0.014376\n",
      "Train Epoch: 16 [ 43000/60000 (72%)]\tLoss: 0.039339\n",
      "Train Epoch: 16 [ 44000/60000 (73%)]\tLoss: 0.071382\n",
      "Train Epoch: 16 [ 45000/60000 (75%)]\tLoss: 0.035572\n",
      "Train Epoch: 16 [ 46000/60000 (77%)]\tLoss: 0.025872\n",
      "Train Epoch: 16 [ 47000/60000 (78%)]\tLoss: 0.061048\n",
      "Train Epoch: 16 [ 48000/60000 (80%)]\tLoss: 0.004371\n",
      "Train Epoch: 16 [ 49000/60000 (82%)]\tLoss: 0.014329\n",
      "Train Epoch: 16 [ 50000/60000 (83%)]\tLoss: 0.055315\n",
      "Train Epoch: 16 [ 51000/60000 (85%)]\tLoss: 0.053775\n",
      "Train Epoch: 16 [ 52000/60000 (87%)]\tLoss: 0.143265\n",
      "Train Epoch: 16 [ 53000/60000 (88%)]\tLoss: 0.005438\n",
      "Train Epoch: 16 [ 54000/60000 (90%)]\tLoss: 0.023397\n",
      "Train Epoch: 16 [ 55000/60000 (92%)]\tLoss: 0.010048\n",
      "Train Epoch: 16 [ 56000/60000 (93%)]\tLoss: 0.013621\n",
      "Train Epoch: 16 [ 57000/60000 (95%)]\tLoss: 0.026078\n",
      "Train Epoch: 16 [ 58000/60000 (97%)]\tLoss: 0.021943\n",
      "Train Epoch: 16 [ 59000/60000 (98%)]\tLoss: 0.078249\n",
      "Train Epoch: 16 [ 60000/60000 (100%)]\tLoss: 0.133385\n",
      "\n",
      "Test Set: Avg. loss: 0.0398, Accuracy: 9871/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [  1000/60000 (2%)]\tLoss: 0.056477\n",
      "Train Epoch: 17 [  2000/60000 (3%)]\tLoss: 0.026112\n",
      "Train Epoch: 17 [  3000/60000 (5%)]\tLoss: 0.038648\n",
      "Train Epoch: 17 [  4000/60000 (7%)]\tLoss: 0.028055\n",
      "Train Epoch: 17 [  5000/60000 (8%)]\tLoss: 0.102332\n",
      "Train Epoch: 17 [  6000/60000 (10%)]\tLoss: 0.041534\n",
      "Train Epoch: 17 [  7000/60000 (12%)]\tLoss: 0.022829\n",
      "Train Epoch: 17 [  8000/60000 (13%)]\tLoss: 0.078004\n",
      "Train Epoch: 17 [  9000/60000 (15%)]\tLoss: 0.006531\n",
      "Train Epoch: 17 [ 10000/60000 (17%)]\tLoss: 0.017897\n",
      "Train Epoch: 17 [ 11000/60000 (18%)]\tLoss: 0.082074\n",
      "Train Epoch: 17 [ 12000/60000 (20%)]\tLoss: 0.018777\n",
      "Train Epoch: 17 [ 13000/60000 (22%)]\tLoss: 0.031813\n",
      "Train Epoch: 17 [ 14000/60000 (23%)]\tLoss: 0.037134\n",
      "Train Epoch: 17 [ 15000/60000 (25%)]\tLoss: 0.037053\n",
      "Train Epoch: 17 [ 16000/60000 (27%)]\tLoss: 0.022200\n",
      "Train Epoch: 17 [ 17000/60000 (28%)]\tLoss: 0.009310\n",
      "Train Epoch: 17 [ 18000/60000 (30%)]\tLoss: 0.041835\n",
      "Train Epoch: 17 [ 19000/60000 (32%)]\tLoss: 0.010998\n",
      "Train Epoch: 17 [ 20000/60000 (33%)]\tLoss: 0.043281\n",
      "Train Epoch: 17 [ 21000/60000 (35%)]\tLoss: 0.027411\n",
      "Train Epoch: 17 [ 22000/60000 (37%)]\tLoss: 0.029014\n",
      "Train Epoch: 17 [ 23000/60000 (38%)]\tLoss: 0.019723\n",
      "Train Epoch: 17 [ 24000/60000 (40%)]\tLoss: 0.042261\n",
      "Train Epoch: 17 [ 25000/60000 (42%)]\tLoss: 0.082841\n",
      "Train Epoch: 17 [ 26000/60000 (43%)]\tLoss: 0.056824\n",
      "Train Epoch: 17 [ 27000/60000 (45%)]\tLoss: 0.014993\n",
      "Train Epoch: 17 [ 28000/60000 (47%)]\tLoss: 0.020250\n",
      "Train Epoch: 17 [ 29000/60000 (48%)]\tLoss: 0.016495\n",
      "Train Epoch: 17 [ 30000/60000 (50%)]\tLoss: 0.018939\n",
      "Train Epoch: 17 [ 31000/60000 (52%)]\tLoss: 0.011159\n",
      "Train Epoch: 17 [ 32000/60000 (53%)]\tLoss: 0.018870\n",
      "Train Epoch: 17 [ 33000/60000 (55%)]\tLoss: 0.020078\n",
      "Train Epoch: 17 [ 34000/60000 (57%)]\tLoss: 0.113688\n",
      "Train Epoch: 17 [ 35000/60000 (58%)]\tLoss: 0.021250\n",
      "Train Epoch: 17 [ 36000/60000 (60%)]\tLoss: 0.031364\n",
      "Train Epoch: 17 [ 37000/60000 (62%)]\tLoss: 0.023129\n",
      "Train Epoch: 17 [ 38000/60000 (63%)]\tLoss: 0.028554\n",
      "Train Epoch: 17 [ 39000/60000 (65%)]\tLoss: 0.031970\n",
      "Train Epoch: 17 [ 40000/60000 (67%)]\tLoss: 0.036015\n",
      "Train Epoch: 17 [ 41000/60000 (68%)]\tLoss: 0.022744\n",
      "Train Epoch: 17 [ 42000/60000 (70%)]\tLoss: 0.035964\n",
      "Train Epoch: 17 [ 43000/60000 (72%)]\tLoss: 0.014208\n",
      "Train Epoch: 17 [ 44000/60000 (73%)]\tLoss: 0.053608\n",
      "Train Epoch: 17 [ 45000/60000 (75%)]\tLoss: 0.056247\n",
      "Train Epoch: 17 [ 46000/60000 (77%)]\tLoss: 0.020349\n",
      "Train Epoch: 17 [ 47000/60000 (78%)]\tLoss: 0.015790\n",
      "Train Epoch: 17 [ 48000/60000 (80%)]\tLoss: 0.049588\n",
      "Train Epoch: 17 [ 49000/60000 (82%)]\tLoss: 0.019488\n",
      "Train Epoch: 17 [ 50000/60000 (83%)]\tLoss: 0.032509\n",
      "Train Epoch: 17 [ 51000/60000 (85%)]\tLoss: 0.053122\n",
      "Train Epoch: 17 [ 52000/60000 (87%)]\tLoss: 0.023116\n",
      "Train Epoch: 17 [ 53000/60000 (88%)]\tLoss: 0.054339\n",
      "Train Epoch: 17 [ 54000/60000 (90%)]\tLoss: 0.033323\n",
      "Train Epoch: 17 [ 55000/60000 (92%)]\tLoss: 0.026286\n",
      "Train Epoch: 17 [ 56000/60000 (93%)]\tLoss: 0.010328\n",
      "Train Epoch: 17 [ 57000/60000 (95%)]\tLoss: 0.010380\n",
      "Train Epoch: 17 [ 58000/60000 (97%)]\tLoss: 0.083440\n",
      "Train Epoch: 17 [ 59000/60000 (98%)]\tLoss: 0.071518\n",
      "Train Epoch: 17 [ 60000/60000 (100%)]\tLoss: 0.037397\n",
      "\n",
      "Test Set: Avg. loss: 0.0397, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [  1000/60000 (2%)]\tLoss: 0.043963\n",
      "Train Epoch: 18 [  2000/60000 (3%)]\tLoss: 0.015989\n",
      "Train Epoch: 18 [  3000/60000 (5%)]\tLoss: 0.115702\n",
      "Train Epoch: 18 [  4000/60000 (7%)]\tLoss: 0.016766\n",
      "Train Epoch: 18 [  5000/60000 (8%)]\tLoss: 0.027345\n",
      "Train Epoch: 18 [  6000/60000 (10%)]\tLoss: 0.015182\n",
      "Train Epoch: 18 [  7000/60000 (12%)]\tLoss: 0.027437\n",
      "Train Epoch: 18 [  8000/60000 (13%)]\tLoss: 0.049527\n",
      "Train Epoch: 18 [  9000/60000 (15%)]\tLoss: 0.012670\n",
      "Train Epoch: 18 [ 10000/60000 (17%)]\tLoss: 0.046596\n",
      "Train Epoch: 18 [ 11000/60000 (18%)]\tLoss: 0.056221\n",
      "Train Epoch: 18 [ 12000/60000 (20%)]\tLoss: 0.030182\n",
      "Train Epoch: 18 [ 13000/60000 (22%)]\tLoss: 0.024704\n",
      "Train Epoch: 18 [ 14000/60000 (23%)]\tLoss: 0.061149\n",
      "Train Epoch: 18 [ 15000/60000 (25%)]\tLoss: 0.006862\n",
      "Train Epoch: 18 [ 16000/60000 (27%)]\tLoss: 0.023055\n",
      "Train Epoch: 18 [ 17000/60000 (28%)]\tLoss: 0.029952\n",
      "Train Epoch: 18 [ 18000/60000 (30%)]\tLoss: 0.047563\n",
      "Train Epoch: 18 [ 19000/60000 (32%)]\tLoss: 0.015119\n",
      "Train Epoch: 18 [ 20000/60000 (33%)]\tLoss: 0.079599\n",
      "Train Epoch: 18 [ 21000/60000 (35%)]\tLoss: 0.016528\n",
      "Train Epoch: 18 [ 22000/60000 (37%)]\tLoss: 0.008364\n",
      "Train Epoch: 18 [ 23000/60000 (38%)]\tLoss: 0.025670\n",
      "Train Epoch: 18 [ 24000/60000 (40%)]\tLoss: 0.034107\n",
      "Train Epoch: 18 [ 25000/60000 (42%)]\tLoss: 0.020891\n",
      "Train Epoch: 18 [ 26000/60000 (43%)]\tLoss: 0.043224\n",
      "Train Epoch: 18 [ 27000/60000 (45%)]\tLoss: 0.069143\n",
      "Train Epoch: 18 [ 28000/60000 (47%)]\tLoss: 0.086508\n",
      "Train Epoch: 18 [ 29000/60000 (48%)]\tLoss: 0.108800\n",
      "Train Epoch: 18 [ 30000/60000 (50%)]\tLoss: 0.009850\n",
      "Train Epoch: 18 [ 31000/60000 (52%)]\tLoss: 0.041072\n",
      "Train Epoch: 18 [ 32000/60000 (53%)]\tLoss: 0.043021\n",
      "Train Epoch: 18 [ 33000/60000 (55%)]\tLoss: 0.016211\n",
      "Train Epoch: 18 [ 34000/60000 (57%)]\tLoss: 0.020581\n",
      "Train Epoch: 18 [ 35000/60000 (58%)]\tLoss: 0.021577\n",
      "Train Epoch: 18 [ 36000/60000 (60%)]\tLoss: 0.027591\n",
      "Train Epoch: 18 [ 37000/60000 (62%)]\tLoss: 0.006285\n",
      "Train Epoch: 18 [ 38000/60000 (63%)]\tLoss: 0.079674\n",
      "Train Epoch: 18 [ 39000/60000 (65%)]\tLoss: 0.075655\n",
      "Train Epoch: 18 [ 40000/60000 (67%)]\tLoss: 0.088038\n",
      "Train Epoch: 18 [ 41000/60000 (68%)]\tLoss: 0.065106\n",
      "Train Epoch: 18 [ 42000/60000 (70%)]\tLoss: 0.005687\n",
      "Train Epoch: 18 [ 43000/60000 (72%)]\tLoss: 0.052437\n",
      "Train Epoch: 18 [ 44000/60000 (73%)]\tLoss: 0.049728\n",
      "Train Epoch: 18 [ 45000/60000 (75%)]\tLoss: 0.004259\n",
      "Train Epoch: 18 [ 46000/60000 (77%)]\tLoss: 0.015581\n",
      "Train Epoch: 18 [ 47000/60000 (78%)]\tLoss: 0.047340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [ 48000/60000 (80%)]\tLoss: 0.023380\n",
      "Train Epoch: 18 [ 49000/60000 (82%)]\tLoss: 0.059145\n",
      "Train Epoch: 18 [ 50000/60000 (83%)]\tLoss: 0.015423\n",
      "Train Epoch: 18 [ 51000/60000 (85%)]\tLoss: 0.026947\n",
      "Train Epoch: 18 [ 52000/60000 (87%)]\tLoss: 0.015179\n",
      "Train Epoch: 18 [ 53000/60000 (88%)]\tLoss: 0.011145\n",
      "Train Epoch: 18 [ 54000/60000 (90%)]\tLoss: 0.058597\n",
      "Train Epoch: 18 [ 55000/60000 (92%)]\tLoss: 0.026145\n",
      "Train Epoch: 18 [ 56000/60000 (93%)]\tLoss: 0.054591\n",
      "Train Epoch: 18 [ 57000/60000 (95%)]\tLoss: 0.017842\n",
      "Train Epoch: 18 [ 58000/60000 (97%)]\tLoss: 0.022105\n",
      "Train Epoch: 18 [ 59000/60000 (98%)]\tLoss: 0.097399\n",
      "Train Epoch: 18 [ 60000/60000 (100%)]\tLoss: 0.035998\n",
      "\n",
      "Test Set: Avg. loss: 0.0370, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [  1000/60000 (2%)]\tLoss: 0.060774\n",
      "Train Epoch: 19 [  2000/60000 (3%)]\tLoss: 0.017903\n",
      "Train Epoch: 19 [  3000/60000 (5%)]\tLoss: 0.008281\n",
      "Train Epoch: 19 [  4000/60000 (7%)]\tLoss: 0.010013\n",
      "Train Epoch: 19 [  5000/60000 (8%)]\tLoss: 0.026314\n",
      "Train Epoch: 19 [  6000/60000 (10%)]\tLoss: 0.058046\n",
      "Train Epoch: 19 [  7000/60000 (12%)]\tLoss: 0.058460\n",
      "Train Epoch: 19 [  8000/60000 (13%)]\tLoss: 0.069911\n",
      "Train Epoch: 19 [  9000/60000 (15%)]\tLoss: 0.016859\n",
      "Train Epoch: 19 [ 10000/60000 (17%)]\tLoss: 0.018360\n",
      "Train Epoch: 19 [ 11000/60000 (18%)]\tLoss: 0.004798\n",
      "Train Epoch: 19 [ 12000/60000 (20%)]\tLoss: 0.087218\n",
      "Train Epoch: 19 [ 13000/60000 (22%)]\tLoss: 0.031139\n",
      "Train Epoch: 19 [ 14000/60000 (23%)]\tLoss: 0.056034\n",
      "Train Epoch: 19 [ 15000/60000 (25%)]\tLoss: 0.048477\n",
      "Train Epoch: 19 [ 16000/60000 (27%)]\tLoss: 0.009196\n",
      "Train Epoch: 19 [ 17000/60000 (28%)]\tLoss: 0.006166\n",
      "Train Epoch: 19 [ 18000/60000 (30%)]\tLoss: 0.045863\n",
      "Train Epoch: 19 [ 19000/60000 (32%)]\tLoss: 0.007376\n",
      "Train Epoch: 19 [ 20000/60000 (33%)]\tLoss: 0.007265\n",
      "Train Epoch: 19 [ 21000/60000 (35%)]\tLoss: 0.040129\n",
      "Train Epoch: 19 [ 22000/60000 (37%)]\tLoss: 0.009334\n",
      "Train Epoch: 19 [ 23000/60000 (38%)]\tLoss: 0.011330\n",
      "Train Epoch: 19 [ 24000/60000 (40%)]\tLoss: 0.009212\n",
      "Train Epoch: 19 [ 25000/60000 (42%)]\tLoss: 0.017877\n",
      "Train Epoch: 19 [ 26000/60000 (43%)]\tLoss: 0.003940\n",
      "Train Epoch: 19 [ 27000/60000 (45%)]\tLoss: 0.006453\n",
      "Train Epoch: 19 [ 28000/60000 (47%)]\tLoss: 0.029890\n",
      "Train Epoch: 19 [ 29000/60000 (48%)]\tLoss: 0.038642\n",
      "Train Epoch: 19 [ 30000/60000 (50%)]\tLoss: 0.013147\n",
      "Train Epoch: 19 [ 31000/60000 (52%)]\tLoss: 0.058299\n",
      "Train Epoch: 19 [ 32000/60000 (53%)]\tLoss: 0.009708\n",
      "Train Epoch: 19 [ 33000/60000 (55%)]\tLoss: 0.020581\n",
      "Train Epoch: 19 [ 34000/60000 (57%)]\tLoss: 0.024054\n",
      "Train Epoch: 19 [ 35000/60000 (58%)]\tLoss: 0.050498\n",
      "Train Epoch: 19 [ 36000/60000 (60%)]\tLoss: 0.015026\n",
      "Train Epoch: 19 [ 37000/60000 (62%)]\tLoss: 0.014476\n",
      "Train Epoch: 19 [ 38000/60000 (63%)]\tLoss: 0.042236\n",
      "Train Epoch: 19 [ 39000/60000 (65%)]\tLoss: 0.013712\n",
      "Train Epoch: 19 [ 40000/60000 (67%)]\tLoss: 0.082415\n",
      "Train Epoch: 19 [ 41000/60000 (68%)]\tLoss: 0.015792\n",
      "Train Epoch: 19 [ 42000/60000 (70%)]\tLoss: 0.055991\n",
      "Train Epoch: 19 [ 43000/60000 (72%)]\tLoss: 0.057216\n",
      "Train Epoch: 19 [ 44000/60000 (73%)]\tLoss: 0.002143\n",
      "Train Epoch: 19 [ 45000/60000 (75%)]\tLoss: 0.061195\n",
      "Train Epoch: 19 [ 46000/60000 (77%)]\tLoss: 0.027094\n",
      "Train Epoch: 19 [ 47000/60000 (78%)]\tLoss: 0.031693\n",
      "Train Epoch: 19 [ 48000/60000 (80%)]\tLoss: 0.012759\n",
      "Train Epoch: 19 [ 49000/60000 (82%)]\tLoss: 0.028387\n",
      "Train Epoch: 19 [ 50000/60000 (83%)]\tLoss: 0.020610\n",
      "Train Epoch: 19 [ 51000/60000 (85%)]\tLoss: 0.023190\n",
      "Train Epoch: 19 [ 52000/60000 (87%)]\tLoss: 0.040947\n",
      "Train Epoch: 19 [ 53000/60000 (88%)]\tLoss: 0.108579\n",
      "Train Epoch: 19 [ 54000/60000 (90%)]\tLoss: 0.031519\n",
      "Train Epoch: 19 [ 55000/60000 (92%)]\tLoss: 0.008839\n",
      "Train Epoch: 19 [ 56000/60000 (93%)]\tLoss: 0.014248\n",
      "Train Epoch: 19 [ 57000/60000 (95%)]\tLoss: 0.021846\n",
      "Train Epoch: 19 [ 58000/60000 (97%)]\tLoss: 0.036457\n",
      "Train Epoch: 19 [ 59000/60000 (98%)]\tLoss: 0.113163\n",
      "Train Epoch: 19 [ 60000/60000 (100%)]\tLoss: 0.022353\n",
      "\n",
      "Test Set: Avg. loss: 0.0360, Accuracy: 9882/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continued_network = CNN()\n",
    "continued_optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "network_state_dict = torch.load(\"../results/model.pth\")\n",
    "continued_network.load_state_dict(network_state_dict)\n",
    "\n",
    "optimizer_state_dict = torch.load(\"../results/optimizer.pth\")\n",
    "continued_optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "for i in range(11, 20):\n",
    "    test_counter.append(i * len(train_dataset))\n",
    "    train(i)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
